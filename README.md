# è”é‚¦å­¦ä¹ å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±æœºåˆ¶

## Federated Learning with Tier-Constrained Dynamic Gradient Reward

ä¸€ä¸ªåŸºäºæ¢¯åº¦é©±åŠ¨å¥–åŠ±çš„å…¬å¹³è”é‚¦å­¦ä¹ æ¿€åŠ±æœºåˆ¶å®ç°ï¼Œæ”¯æŒå¤šç§Non-IIDåœºæ™¯å’Œè¯„ä¼°æŒ‡æ ‡ã€‚
---

## ğŸ“‘ ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒåˆ›æ–°](#æ ¸å¿ƒåˆ›æ–°)
- [ç†è®ºåŸºç¡€](#ç†è®ºåŸºç¡€)
- [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨æŒ‡å—](#è¯¦ç»†ä½¿ç”¨æŒ‡å—)
- [å®éªŒåœºæ™¯](#å®éªŒåœºæ™¯)
- [è¯„ä¼°æŒ‡æ ‡](#è¯„ä¼°æŒ‡æ ‡)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [å¯è§†åŒ–ç»“æœ](#å¯è§†åŒ–ç»“æœ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å¼•ç”¨](#å¼•ç”¨)
- [è®¸å¯è¯](#è®¸å¯è¯)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåˆ›æ–°çš„è”é‚¦å­¦ä¹ æ¿€åŠ±æœºåˆ¶ â€”â€” **å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±ï¼ˆTier-Constrained Dynamic Gradient Rewardï¼‰**ï¼Œæ—¨åœ¨è§£å†³è”é‚¦å­¦ä¹ ä¸­çš„å…¬å¹³æ€§é—®é¢˜ï¼Œç¡®ä¿ä¸åŒæ•°æ®è´¨é‡çš„å®¢æˆ·ç«¯éƒ½èƒ½ä»è”é‚¦å­¦ä¹ ä¸­å—ç›Šã€‚

### æ ¸å¿ƒæ€æƒ³

ä¼ ç»Ÿè”é‚¦å­¦ä¹ ä¸­ï¼Œé«˜è´¨é‡æ•°æ®çš„å®¢æˆ·ç«¯å¾€å¾€å¯¹å…¨å±€æ¨¡å‹è´¡çŒ®æ›´å¤§ï¼Œä½†ä½è´¨é‡æ•°æ®çš„å®¢æˆ·ç«¯å¯èƒ½æ— æ³•ä»è”é‚¦å­¦ä¹ ä¸­è·ç›Šï¼Œç”šè‡³æ€§èƒ½ä¸‹é™ã€‚æœ¬é¡¹ç›®é€šè¿‡**å·®å¼‚åŒ–æ¢¯åº¦åˆ†å‘**æœºåˆ¶ï¼š
- é«˜è´¡çŒ®å®¢æˆ·ç«¯è·å¾—æ›´å®Œæ•´çš„æ¨¡å‹æ›´æ–°
- ä½è´¡çŒ®å®¢æˆ·ç«¯è·å¾—ç¨€ç–åŒ–çš„æ¨¡å‹æ›´æ–°
- é€šè¿‡å±‚çº§çº¦æŸç¡®ä¿æ¿€åŠ±æœºåˆ¶çš„å…¬å¹³æ€§å’Œæœ‰æ•ˆæ€§

### åŸºäºè®ºæ–‡

æœ¬å®ç°åŸºäº NeurIPS 2021 è®ºæ–‡ï¼š
> **"Gradient-Driven Rewards to Guarantee Fairness in Collaborative Machine Learning"**

å¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œäº†é‡è¦æ‰©å±•å’Œä¼˜åŒ–ã€‚

---

## ğŸš€ æ ¸å¿ƒåˆ›æ–°

### 1. å±‚çº§çº¦æŸç¨€ç–åŒ–ï¼ˆTier-Constrained Sparsificationï¼‰

**ä¼ ç»Ÿæ–¹æ³•çš„é—®é¢˜**ï¼šå›ºå®šç¨€ç–ç‡æ— æ³•åæ˜ å®¢æˆ·ç«¯è´¡çŒ®åº¦çš„ç»†å¾®å·®å¼‚

**æœ¬é¡¹ç›®çš„è§£å†³æ–¹æ¡ˆ**ï¼š
```
ä¼ ç»Ÿæ–¹æ³•ï¼šGold = 80% ä¿ç•™ç‡ï¼ˆå›ºå®šï¼‰
         Silver = 50% ä¿ç•™ç‡ï¼ˆå›ºå®šï¼‰
         Bronze = 30% ä¿ç•™ç‡ï¼ˆå›ºå®šï¼‰

æœ¬é¡¹ç›®ï¼šGold = [80%, 100%] ä¿ç•™ç‡èŒƒå›´
       Silver = [50%, 80%] ä¿ç•™ç‡èŒƒå›´
       Bronze = [10%, 50%] ä¿ç•™ç‡èŒƒå›´
       + ç»„å†…æ’å€¼å®ç°è¿ç»­æ˜ å°„
```

### 2. ç»„å†…çº¿æ€§æ’å€¼ï¼ˆIntra-Tier Interpolationï¼‰

åœ¨æ¯ä¸ªå±‚çº§å†…éƒ¨ï¼Œæ ¹æ®å®¢æˆ·ç«¯çš„ç›¸å¯¹è´¡çŒ®åº¦è¿›è¡Œçº¿æ€§æ’å€¼ï¼š

```
ç›¸å¯¹ä½ç½® P_i = (Ï†_i - min(Ï† âˆˆ L)) / (max(Ï† âˆˆ L) - min(Ï† âˆˆ L))
ä¿ç•™ç‡ s_i = S^L_low + P_i Ã— (S^L_high - S^L_low)
```

è¿™ä½¿å¾—å³ä½¿åœ¨åŒä¸€å±‚çº§å†…ï¼Œä¸åŒè´¡çŒ®åº¦çš„å®¢æˆ·ç«¯ä¹Ÿèƒ½è·å¾—å·®å¼‚åŒ–çš„æ¨¡å‹æ›´æ–°ã€‚

### 3. åŸºäºå¹…åº¦çš„ç¨€ç–åŒ–ï¼ˆMagnitude-Based Pruningï¼‰

ä¿ç•™æ¢¯åº¦ä¸­ç»å¯¹å€¼æœ€å¤§çš„å‚æ•°ï¼Œç¡®ä¿å³ä½¿ä½è´¨é‡å®¢æˆ·ç«¯è·å¾—ç¨€ç–æ›´æ–°ï¼Œä¹Ÿèƒ½è·å–æ¨¡å‹æœ€é‡è¦çš„ç‰¹å¾ï¼š

```python
# é€‰æ‹© top-k é‡è¦å‚æ•°
abs_grad = torch.abs(gradient)
threshold = torch.topk(abs_grad, num_keep).values[-1]
sparse_gradient = gradient * (abs_grad >= threshold)
```

### 4. è´¡çŒ®åº¦åŠ æƒèšåˆï¼ˆContribution-Aware Aggregationï¼‰

ä½¿ç”¨ Softmax å½’ä¸€åŒ–çš„è´¡çŒ®åº¦ä½œä¸ºèšåˆæƒé‡ï¼Œè€Œéç®€å•çš„æ ·æœ¬æ•°é‡ï¼š

```
w_i = exp(Î² * Ï†_i) / Î£ exp(Î² * Ï†_k)
Î”w_global = Î£ w_i * Î”w_i
```

---

## ğŸ“š ç†è®ºåŸºç¡€

### CGSVï¼ˆCosine Gradient Shapley Valueï¼‰

æœ¬é¡¹ç›®ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿‘ä¼¼ Shapley Value æ¥è®¡ç®—å®¢æˆ·ç«¯è´¡çŒ®åº¦ï¼š

```
CGSV_i â‰ˆ cos(Î”w_i, Î”w_global) = (Î”w_i Â· Î”w_global) / (||Î”w_i|| Ã— ||Î”w_global||)
```

**ä¼˜åŠ¿**ï¼š
- è®¡ç®—å¤æ‚åº¦ä½ï¼šO(n) vs Shapley Value çš„ O(2^n)
- å¯è§£é‡Šæ€§å¼ºï¼šç›´æ¥åæ˜ æ¢¯åº¦æ–¹å‘çš„ä¸€è‡´æ€§
- å½’ä¸€åŒ–åˆ° [0, 1]ï¼šä¾¿äºè·¨è½®æ¬¡æ¯”è¾ƒ

### ä¸‰çº§ä¼šå‘˜ç³»ç»Ÿ

åŸºäºç´¯ç§¯ä¿¡èª‰åˆ†ï¼ˆAccumulated Reputationï¼‰çš„ç›¸å¯¹æ’åï¼š

| ç­‰çº§ | æ’åç™¾åˆ†ä½ | ä¿ç•™ç‡èŒƒå›´ | æ¯”ä¾‹ |
|------|-----------|-----------|------|
| **Gold** | â‰¥ 80% | [80%, 100%] | Top 20% |
| **Silver** | [50%, 80%) | [50%, 80%] | Next 30% |
| **Bronze** | < 50% | [10%, 50%] | Bottom 50% |

### æ—¶é—´ç‰‡ç®¡ç†

ç§¯åˆ†å®æ—¶ç´¯åŠ ï¼Œé˜¶æ®µæ€§å¤±æ•ˆï¼š
- **æ—¶é—´ç‰‡å¤§å°**ï¼š5 è½®ï¼ˆå¯é…ç½®ï¼‰
- **æœ‰æ•ˆæœŸ**ï¼š2 ä¸ªæ—¶é—´ç‰‡ï¼ˆå¯é…ç½®ï¼‰
- **ç§¯åˆ†è®¡ç®—**ï¼šcontribution Ã— 1000

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æ•´ä½“æµç¨‹

```mermaid
graph LR
    A[å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ] --> B[ä¸Šä¼ è®­ç»ƒåæƒé‡]
    B --> C[æœåŠ¡å™¨è®¡ç®—æ¢¯åº¦]
    C --> D[èšåˆå…¨å±€æ¢¯åº¦]
    D --> E[è®¡ç®—CGSVè´¡çŒ®åº¦]
    E --> F[æ›´æ–°ä¼šå‘˜ç­‰çº§]
    F --> G[å±‚çº§çº¦æŸç¨€ç–åŒ–]
    G --> H[åˆ†å‘ç¨€ç–æ¢¯åº¦]
    H --> I[å®¢æˆ·ç«¯åº”ç”¨æ›´æ–°]
    I --> A
```

### æ ¸å¿ƒç»„ä»¶

```
federated/
â”œâ”€â”€ server.py          # è”é‚¦å­¦ä¹ æœåŠ¡å™¨
â”‚   â”œâ”€â”€ æ”¶é›†å®¢æˆ·ç«¯æ¢¯åº¦
â”‚   â”œâ”€â”€ èšåˆå…¨å±€æ¢¯åº¦
â”‚   â”œâ”€â”€ è®¡ç®—CGSVè´¡çŒ®åº¦
â”‚   â””â”€â”€ å·®å¼‚åŒ–æ¢¯åº¦åˆ†å‘
â””â”€â”€ client.py          # è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯
    â”œâ”€â”€ æœ¬åœ°è®­ç»ƒ
    â”œâ”€â”€ åº”ç”¨ç¨€ç–æ¢¯åº¦
    â””â”€â”€ æ€§èƒ½è¯„ä¼°

incentive/
â”œâ”€â”€ points_calculator.py      # CGSVè®¡ç®—å™¨
â”œâ”€â”€ membership.py             # ä¼šå‘˜ç­‰çº§ç³»ç»Ÿ
â”œâ”€â”€ time_slice.py            # æ—¶é—´ç‰‡ç®¡ç†
â”œâ”€â”€ sparsification_distributor.py  # ç¨€ç–åŒ–åˆ†å‘å™¨
â””â”€â”€ differentiated_model.py  # UPSMåˆ†å‘å™¨ï¼ˆå¤‡é€‰ï¼‰
```

---

## ğŸ’» ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- CUDA 11.0+ (GPUæ¨è)
- 8GB+ RAM
- 10GB+ ç£ç›˜ç©ºé—´

### å®‰è£…æ­¥éª¤

1. **å…‹éš†ä»“åº“**
```bash
git clone https://github.com/yourusername/federated-learning-incentive.git
cd federated-learning-incentive
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**ï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨ conda
conda create -n fl-incentive python=3.8
conda activate fl-incentive

# æˆ–ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows
```

3. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

### ä¾èµ–åŒ…

```
torch>=1.9.0
torchvision>=0.10.0
numpy>=1.19.5
matplotlib>=3.3.4
seaborn>=0.11.2
tqdm>=4.62.3
scikit-learn>=0.24.2
pandas>=1.3.3
Pillow>=8.3.2
```

---

## ğŸ® å¿«é€Ÿå¼€å§‹

### åŸºç¡€å®éªŒ

è¿è¡Œé»˜è®¤é…ç½®çš„å®éªŒï¼ˆCIFAR-10 + Non-IID Dirichletï¼‰ï¼š

```bash
python main.py
```

### è‡ªå®šä¹‰å®éªŒ

```bash
python main.py \
    --dataset cifar10 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --num_clients 100 \
    --num_rounds 50 \
    --tier_config default \
    --sparsification_mode magnitude \
    --aggregation_method contribution
```

### æŸ¥çœ‹å¸®åŠ©

```bash
python main.py --help
```

---

## ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—

### åœºæ™¯ä¸€ï¼šIID åŸºå‡†å®éªŒ

æµ‹è¯•åœ¨ç†æƒ³çš„ç‹¬ç«‹åŒåˆ†å¸ƒç¯å¢ƒä¸‹çš„æ€§èƒ½ï¼š

```bash
python main.py \
    --dataset cifar10 \
    --distribution iid \
    --num_clients 100 \
    --num_rounds 50
```

### åœºæ™¯äºŒï¼šNon-IID Dirichletï¼ˆæ ‡ç­¾åˆ†å¸ƒå€¾æ–œï¼‰

æ¨¡æ‹Ÿå®¢æˆ·ç«¯æ•°æ®æ ‡ç­¾åˆ†å¸ƒä¸å‡çš„åœºæ™¯ï¼š

```bash
# é«˜åº¦å¼‚è´¨æ€§ï¼ˆalpha=0.1ï¼‰
python main.py \
    --dataset cifar10 \
    --distribution non-iid-dir \
    --alpha 0.1 \
    --num_clients 100 \
    --num_rounds 50

# ä¸­ç­‰å¼‚è´¨æ€§ï¼ˆalpha=0.5ï¼Œæ¨èï¼‰
python main.py \
    --dataset cifar10 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --num_clients 100 \
    --num_rounds 50
```

**Alpha å‚æ•°è¯´æ˜**ï¼š
- `alpha = 0.1`ï¼šé«˜åº¦ Non-IIDï¼Œæ•°æ®æåº¦ä¸å‡è¡¡
- `alpha = 0.5`ï¼šä¸­ç­‰ Non-IIDï¼ˆæ¨èï¼‰
- `alpha = 1.0`ï¼šæ¥è¿‘ IID

### åœºæ™¯ä¸‰ï¼šNon-IID Sizeï¼ˆæ•°æ®é‡ä¸å¹³è¡¡ï¼‰

æ¨¡æ‹Ÿå®¢æˆ·ç«¯æ‹¥æœ‰ä¸åŒæ•°é‡æ•°æ®çš„åœºæ™¯ï¼š

```bash
python main.py \
    --dataset cifar10 \
    --distribution non-iid-size \
    --size_imbalance_ratio 5.0 \
    --num_clients 100 \
    --num_rounds 50
```

**Size Imbalance Ratio è¯´æ˜**ï¼š
- è¡¨ç¤ºæœ€å¤§æ•°æ®é‡ä¸æœ€å°æ•°æ®é‡çš„æ¯”ä¾‹
- `5.0`ï¼šæœ€å¤§å®¢æˆ·ç«¯çš„æ•°æ®é‡æ˜¯æœ€å°å®¢æˆ·ç«¯çš„ 5 å€
- `10.0`ï¼šæ›´æç«¯çš„ä¸å¹³è¡¡

### åœºæ™¯å››ï¼šNon-IID Classï¼ˆç±»åˆ«æ•°ä¸å¹³è¡¡ï¼‰

æ¨¡æ‹Ÿå®¢æˆ·ç«¯æ‹¥æœ‰ä¸åŒæ•°é‡ç±»åˆ«çš„åœºæ™¯ï¼š

```bash
python main.py \
    --dataset cifar10 \
    --distribution non-iid-class \
    --min_classes_per_client 2 \
    --max_classes_per_client 5 \
    --num_clients 100 \
    --num_rounds 50
```

### å±‚çº§é…ç½®å¯¹æ¯”å®éªŒ

#### 1. é»˜è®¤é…ç½®ï¼ˆæ¨èï¼‰

```bash
python main.py \
    --dataset cifar10 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --tier_config default
```

ä¿ç•™ç‡èŒƒå›´ï¼š
- Gold: [80%, 100%]
- Silver: [50%, 80%]
- Bronze: [10%, 50%]

#### 2. æ¿€è¿›é…ç½®ï¼ˆæ›´å¤§å·®å¼‚åŒ–ï¼‰

```bash
python main.py \
    --dataset cifar10 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --tier_config aggressive
```

ä¿ç•™ç‡èŒƒå›´ï¼š
- Gold: [90%, 100%]
- Silver: [60%, 90%]
- Bronze: [10%, 60%]

**é€‚ç”¨åœºæ™¯**ï¼šæƒ³è¦æé«˜ PCCï¼ˆè´¡çŒ®-æ”¶ç›Šç›¸å…³æ€§ï¼‰

#### 3. æ¸©å’Œé…ç½®ï¼ˆæ›´å‡è¡¡ï¼‰

```bash
python main.py \
    --dataset cifar10 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --tier_config moderate
```

ä¿ç•™ç‡èŒƒå›´ï¼š
- Gold: [70%, 100%]
- Silver: [40%, 70%]
- Bronze: [20%, 40%]

**é€‚ç”¨åœºæ™¯**ï¼šæƒ³è¦æé«˜ IPRï¼ˆæ¿€åŠ±å‚ä¸ç‡ï¼‰

### ç¨€ç–åŒ–æ¨¡å¼å¯¹æ¯”

#### 1. åŸºäºå¹…åº¦ï¼ˆæ¨èï¼‰

```bash
python main.py \
    --sparsification_mode magnitude
```

ä¿ç•™ç»å¯¹å€¼æœ€å¤§çš„å‚æ•°ï¼Œç¡®ä¿é‡è¦ç‰¹å¾è¢«ä¼ é€’ã€‚

#### 2. éšæœºç¨€ç–åŒ–

```bash
python main.py \
    --sparsification_mode random
```

éšæœºé€‰æ‹©è¦ä¿ç•™çš„å‚æ•°ï¼ˆå¯¹ç…§å®éªŒç”¨ï¼‰ã€‚

#### 3. ç»“æ„åŒ–ç¨€ç–åŒ–

```bash
python main.py \
    --sparsification_mode structured
```

æŒ‰é€šé“/æ»¤æ³¢å™¨è¿›è¡Œç¨€ç–åŒ–ï¼ˆé€‚ç”¨äºå·ç§¯ç½‘ç»œï¼‰ã€‚

### èšåˆæ–¹å¼å¯¹æ¯”

#### 1. è´¡çŒ®åº¦åŠ æƒï¼ˆæ¨èï¼‰

```bash
python main.py \
    --aggregation_method contribution
```

ä½¿ç”¨ CGSV è´¡çŒ®åº¦ä½œä¸ºèšåˆæƒé‡ã€‚

#### 2. FedAvgï¼ˆåŸºçº¿ï¼‰

```bash
python main.py \
    --aggregation_method fedavg
```

ä½¿ç”¨æ ·æœ¬æ•°é‡ä½œä¸ºèšåˆæƒé‡ã€‚

### æ”¯æŒçš„æ•°æ®é›†

```bash
# å›¾åƒæ•°æ®é›†
--dataset mnist           # MNIST æ‰‹å†™æ•°å­—
--dataset fashion-mnist   # Fashion-MNIST
--dataset cifar10         # CIFAR-10ï¼ˆ10ç±»ï¼‰
--dataset cifar100        # CIFAR-100ï¼ˆ100ç±»ï¼Œä½¿ç”¨ResNet18ï¼‰

# æ–‡æœ¬æ•°æ®é›†
--dataset mr             # Movie Review æƒ…æ„Ÿåˆ†æ
--dataset sst            # Stanford Sentiment Treebank
```

---

## ğŸ§ª å®éªŒåœºæ™¯

### æ”¯æŒçš„ Non-IID åœºæ™¯

| åœºæ™¯ç±»å‹ | æè¿° | å‚æ•° | ç°å®åœºæ™¯ä¸¾ä¾‹ |
|---------|------|------|------------|
| **IID** | ç‹¬ç«‹åŒåˆ†å¸ƒ | `--distribution iid` | ç†æƒ³åŒ–å®éªŒåŸºå‡† |
| **Non-IID Dirichlet** | æ ‡ç­¾åˆ†å¸ƒå€¾æ–œ | `--distribution non-iid-dir --alpha 0.5` | ä¸åŒåŒ»é™¢çš„ç–¾ç—…åˆ†å¸ƒå·®å¼‚ |
| **Non-IID Size** | æ•°æ®é‡ä¸å¹³è¡¡ | `--distribution non-iid-size --size_imbalance_ratio 5.0` | å¤§åŒ»é™¢ vs å°è¯Šæ‰€çš„æ•°æ®é‡å·®å¼‚ |
| **Non-IID Class** | ç±»åˆ«æ•°ä¸å¹³è¡¡ | `--distribution non-iid-class --min_classes_per_client 2 --max_classes_per_client 5` | ä¸“ç§‘åŒ»é™¢åªçœ‹ç‰¹å®šç–¾ç—… |

### å®Œæ•´å‚æ•°ç¤ºä¾‹

```bash
python main.py \
    --dataset cifar100 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --num_clients 100 \
    --num_rounds 100 \
    --local_epochs 5 \
    --batch_size 32 \
    --learning_rate 0.01 \
    --gradient_lr 1.0 \
    --standalone_epochs 20 \
    --rounds_per_slice 5 \
    --tier_config aggressive \
    --sparsification_mode magnitude \
    --aggregation_method contribution \
    --seed 42
```

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### 1. PCC (Pearson Correlation Coefficient)

**å®šä¹‰**ï¼šç‹¬ç«‹è®­ç»ƒå‡†ç¡®ç‡ä¸è”é‚¦å­¦ä¹ å‡†ç¡®ç‡çš„çš®å°”é€Šç›¸å…³ç³»æ•°

**å…¬å¼**ï¼š
```
PCC = Cov(Standalone, Federated) / (Ïƒ_standalone Ã— Ïƒ_federated)
```

**è§£è¯»**ï¼š
- `PCC â‰¥ 0.75`ï¼šâœ… æå¥½ï¼å¼ºæ­£ç›¸å…³ï¼Œæ¿€åŠ±æœºåˆ¶æ•ˆæœæ˜¾è‘—
- `PCC â‰¥ 0.65`ï¼šâœ… è‰¯å¥½ï¼ä¸­ç­‰æ­£ç›¸å…³ï¼Œæ¿€åŠ±æœºåˆ¶æœ‰æ•ˆ
- `PCC â‰¥ 0.50`ï¼šâš ï¸ ä¸€èˆ¬ï¼Œå¼±æ­£ç›¸å…³ï¼Œå»ºè®®ä½¿ç”¨ aggressive é…ç½®
- `PCC < 0.50`ï¼šâŒ éœ€è¦æ”¹è¿›

**æ„ä¹‰**ï¼šè¡¡é‡"é«˜è´¡çŒ®å®¢æˆ·ç«¯æ˜¯å¦è·å¾—æ›´å¥½æ€§èƒ½"

### 2. IPR (Incentivized Participation Rate)

**å®šä¹‰**ï¼šè”é‚¦å­¦ä¹ å‡†ç¡®ç‡ â‰¥ ç‹¬ç«‹è®­ç»ƒå‡†ç¡®ç‡çš„å®¢æˆ·ç«¯æ¯”ä¾‹

**å…¬å¼**ï¼š
```
IPR = (æ»¡è¶³ Perf_FL,i â‰¥ Perf_standalone,i çš„å®¢æˆ·ç«¯æ•°) / æ€»å®¢æˆ·ç«¯æ•°
```

**è§£è¯»**ï¼š
- `IPR â‰¥ 0.95`ï¼šâœ… æå¥½ï¼å‡ ä¹æ‰€æœ‰å®¢æˆ·ç«¯å—ç›Š
- `IPR â‰¥ 0.80`ï¼šâœ… è‰¯å¥½ï¼å¤§å¤šæ•°å®¢æˆ·ç«¯å—ç›Š
- `IPR â‰¥ 0.60`ï¼šâš ï¸ ä¸­ç­‰ï¼Œè¾ƒå¤šå®¢æˆ·ç«¯å—ç›Š
- `IPR < 0.60`ï¼šâŒ è¾ƒä½ï¼Œéœ€è¦æ”¹è¿›æ¿€åŠ±æœºåˆ¶

**æ„ä¹‰**ï¼šè¡¡é‡"å¤šå°‘å®¢æˆ·ç«¯ä»è”é‚¦å­¦ä¹ ä¸­è·ç›Š"

### 3. å®¢æˆ·ç«¯å‡†ç¡®ç‡ç»Ÿè®¡

- **Avg Final Accuracy**ï¼šæœ€ç»ˆè½®æ¬¡çš„å¹³å‡å‡†ç¡®ç‡
- **Max Final Accuracy**ï¼šæœ€é«˜å‡†ç¡®ç‡
- **Min Final Accuracy**ï¼šæœ€ä½å‡†ç¡®ç‡
- **Avg Improvement**ï¼šå¹³å‡æ€§èƒ½æå‡

### 4. æ—¶é—´æ¶ˆè€—

- **Total Time**ï¼šæ€»è®­ç»ƒæ—¶é—´
- **Mean Time per Round**ï¼šæ¯è½®å¹³å‡æ—¶é—´
- **Communication Rounds**ï¼šé€šä¿¡è½®æ¬¡

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
federated-learning-incentive/
â”‚
â”œâ”€â”€ config.py                    # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ FederatedConfig         # è”é‚¦å­¦ä¹ é…ç½®
â”‚   â”œâ”€â”€ IncentiveConfig         # æ¿€åŠ±æœºåˆ¶é…ç½®
â”‚   â”œâ”€â”€ DatasetConfig           # æ•°æ®é›†é…ç½®
â”‚   â””â”€â”€ ModelConfig             # æ¨¡å‹é…ç½®
â”‚
â”œâ”€â”€ main.py                      # ä¸»ç¨‹åºå…¥å£
â”‚
â”œâ”€â”€ datasets/                    # æ•°æ®é›†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data_loader.py          # æ•°æ®åŠ è½½å™¨
â”‚       â”œâ”€â”€ FederatedDataLoader # è”é‚¦æ•°æ®åˆ†å‘
â”‚       â”œâ”€â”€ MovieReviewDataset  # MRæ•°æ®é›†
â”‚       â””â”€â”€ SSTDataset          # SSTæ•°æ®é›†
â”‚
â”œâ”€â”€ models/                      # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ cnn_model.py            # CNNæ¨¡å‹
â”‚       â”œâ”€â”€ SimpleCNN           # ç”¨äºMNIST
â”‚       â”œâ”€â”€ CIFARCNN            # ç”¨äºCIFAR-10
â”‚       â”œâ”€â”€ ResNet18/34/50      # ç”¨äºCIFAR-100
â”‚       â”œâ”€â”€ VGG11               # å¤‡é€‰æ¨¡å‹
â”‚       â”œâ”€â”€ TextCNN             # ç”¨äºæ–‡æœ¬åˆ†ç±»
â”‚       â””â”€â”€ ModelFactory        # æ¨¡å‹å·¥å‚
â”‚
â”œâ”€â”€ federated/                   # è”é‚¦å­¦ä¹ æ ¸å¿ƒ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py               # è”é‚¦æœåŠ¡å™¨
â”‚   â”‚   â”œâ”€â”€ collect_client_updates()        # æ”¶é›†æ›´æ–°
â”‚   â”‚   â”œâ”€â”€ update_global_model()           # èšåˆæ¢¯åº¦
â”‚   â”‚   â”œâ”€â”€ calculate_all_contributions()   # è®¡ç®—è´¡çŒ®åº¦
â”‚   â”‚   â””â”€â”€ distribute_sparsified_gradients() # åˆ†å‘ç¨€ç–æ¢¯åº¦
â”‚   â””â”€â”€ client.py               # è”é‚¦å®¢æˆ·ç«¯
â”‚       â”œâ”€â”€ train_federated()   # è”é‚¦è®­ç»ƒ
â”‚       â”œâ”€â”€ apply_gradient_update() # åº”ç”¨æ¢¯åº¦æ›´æ–°
â”‚       â”œâ”€â”€ train_standalone()  # ç‹¬ç«‹è®­ç»ƒåŸºå‡†
â”‚       â””â”€â”€ evaluate()          # æ€§èƒ½è¯„ä¼°
â”‚
â”œâ”€â”€ incentive/                   # æ¿€åŠ±æœºåˆ¶æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ points_calculator.py    # CGSVè®¡ç®—å™¨
â”‚   â”‚   â”œâ”€â”€ flatten_gradient()  # å±•å¹³æ¢¯åº¦
â”‚   â”‚   â”œâ”€â”€ cosine_similarity() # ä½™å¼¦ç›¸ä¼¼åº¦
â”‚   â”‚   â””â”€â”€ calculate_all_contributions() # æ‰¹é‡è®¡ç®—
â”‚   â”œâ”€â”€ membership.py           # ä¼šå‘˜ç­‰çº§ç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ initialize_client() # åˆå§‹åŒ–å®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ update_all_memberships_by_ranking() # æ›´æ–°ç­‰çº§
â”‚   â”‚   â””â”€â”€ get_membership_statistics() # ç»Ÿè®¡ä¿¡æ¯
â”‚   â”œâ”€â”€ time_slice.py          # æ—¶é—´ç‰‡ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ add_contribution_points() # æ·»åŠ ç§¯åˆ†
â”‚   â”‚   â”œâ”€â”€ get_active_points() # è·å–æœ‰æ•ˆç§¯åˆ†
â”‚   â”‚   â””â”€â”€ clean_expired_points() # æ¸…ç†è¿‡æœŸç§¯åˆ†
â”‚   â”œâ”€â”€ sparsification_distributor.py # ç¨€ç–åŒ–åˆ†å‘å™¨ï¼ˆæ ¸å¿ƒï¼‰
â”‚   â”‚   â”œâ”€â”€ assign_clients_to_tiers() # åˆ†é…å±‚çº§
â”‚   â”‚   â”œâ”€â”€ calculate_intra_tier_keep_ratio() # ç»„å†…æ’å€¼
â”‚   â”‚   â”œâ”€â”€ calculate_all_keep_ratios() # è®¡ç®—æ‰€æœ‰ä¿ç•™ç‡
â”‚   â”‚   â”œâ”€â”€ sparsify_gradient_magnitude() # åŸºäºå¹…åº¦ç¨€ç–åŒ–
â”‚   â”‚   â””â”€â”€ distribute_sparsified_gradients() # åˆ†å‘
â”‚   â””â”€â”€ differentiated_model.py # UPSMåˆ†å‘å™¨ï¼ˆå¤‡é€‰ï¼‰
â”‚
â”œâ”€â”€ utils/                       # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py              # æŒ‡æ ‡è®¡ç®—
â”‚   â”‚   â”œâ”€â”€ calculate_pcc()     # è®¡ç®—PCC
â”‚   â”‚   â”œâ”€â”€ calculate_ipr_accuracy() # è®¡ç®—IPR
â”‚   â”‚   â””â”€â”€ calculate_final_metrics() # æœ€ç»ˆæŒ‡æ ‡
â”‚   â””â”€â”€ visualization.py        # å¯è§†åŒ–
â”‚       â”œâ”€â”€ plot_training_curves() # è®­ç»ƒæ›²çº¿
â”‚       â”œâ”€â”€ plot_pcc_scatter()  # PCCæ•£ç‚¹å›¾
â”‚       â”œâ”€â”€ plot_ipr_bar()      # IPRæŸ±çŠ¶å›¾
â”‚       â”œâ”€â”€ plot_ipr_history()  # IPRå†å²
â”‚       â””â”€â”€ plot_comprehensive_summary() # ç»¼åˆæ‘˜è¦
â”‚
â”œâ”€â”€ outputs/                     # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ checkpoints/            # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ logs/                   # æ—¥å¿—æ–‡ä»¶
â”‚   â”œâ”€â”€ plots/                  # å¯è§†åŒ–å›¾è¡¨
â”‚   â””â”€â”€ results/                # å®éªŒç»“æœï¼ˆJSONï¼‰
â”‚
â”œâ”€â”€ requirements.txt            # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ README.md                   # æœ¬æ–‡ä»¶
â””â”€â”€ gpu_check.py               # GPUè¯Šæ–­å·¥å…·
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### æ ¸å¿ƒé…ç½®ç±»

#### 1. FederatedConfigï¼ˆè”é‚¦å­¦ä¹ é…ç½®ï¼‰

```python
NUM_CLIENTS = 100              # å®¢æˆ·ç«¯æ•°é‡
NUM_ROUNDS = 50                # é€šä¿¡è½®æ¬¡
LOCAL_EPOCHS = 1               # æœ¬åœ°è®­ç»ƒè½®æ¬¡
LOCAL_BATCH_SIZE = 32          # æ‰¹æ¬¡å¤§å°
LEARNING_RATE = 0.01           # å­¦ä¹ ç‡
DISTRIBUTION_TYPE = "non-iid-dir"  # æ•°æ®åˆ†å¸ƒç±»å‹
NON_IID_ALPHA = 0.5           # Dirichletå‚æ•°
```

#### 2. IncentiveConfigï¼ˆæ¿€åŠ±æœºåˆ¶é…ç½®ï¼‰

```python
# CGSVé…ç½®
CGSV_EPSILON = 1e-10

# æ—¶é—´ç‰‡é…ç½®
TIME_SLICE_TYPE = "rounds"
ROUNDS_PER_SLICE = 5          # æ¯ä¸ªæ—¶é—´ç‰‡çš„è½®æ¬¡æ•°
POINTS_VALIDITY_SLICES = 2    # ç§¯åˆ†æœ‰æ•ˆæœŸ

# ä¼šå‘˜ç­‰çº§ç™¾åˆ†ä½
LEVEL_PERCENTILES = {
    'gold': 0.80,    # Top 20%
    'silver': 0.50,  # Next 30%
    'bronze': 0.00   # Bottom 50%
}

# å±‚çº§ä¿ç•™ç‡èŒƒå›´ï¼ˆé»˜è®¤é…ç½®ï¼‰
TIER_KEEP_RATIO_RANGES = {
    'gold': (0.80, 1.0),
    'silver': (0.50, 0.80),
    'bronze': (0.10, 0.50)
}

# ç¨€ç–åŒ–æ¨¡å¼
SPARSIFICATION_MODE = "magnitude"  # magnitude/random/structured

# èšåˆæ–¹å¼
AGGREGATION_METHOD = "contribution"  # contribution/fedavg
AGGREGATION_SCALE = 5.0

# ç§»åŠ¨å¹³å‡é…ç½®
MOVING_AVERAGE_ALPHA = 0.95
```

#### 3. DatasetConfigï¼ˆæ•°æ®é›†é…ç½®ï¼‰

```python
AVAILABLE_DATASETS = [
    "mnist", "fashion-mnist", "cifar10", "cifar100",
    "mr", "sst"
]

# å½’ä¸€åŒ–å‚æ•°
NORMALIZE_MEAN = {
    "mnist": (0.1307,),
    "cifar10": (0.4914, 0.4822, 0.4465),
    "cifar100": (0.5071, 0.4867, 0.4408)
}

# ç±»åˆ«æ•°é‡
NUM_CLASSES = {
    "mnist": 10,
    "cifar10": 10,
    "cifar100": 100,
    "mr": 2,
    "sst": 2
}
```

---

## ğŸ“ˆ å¯è§†åŒ–ç»“æœ

å®éªŒå®Œæˆåï¼Œä¼šåœ¨ `outputs/figures/` ç›®å½•ç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–å›¾è¡¨ï¼š

### 1. è®­ç»ƒæ›²çº¿ (`*_training_curves.png`)

åŒ…å« 4 ä¸ªå­å›¾ï¼š
- å®¢æˆ·ç«¯å‡†ç¡®ç‡å˜åŒ–
- CGSV è´¡çŒ®åº¦åˆ†å¸ƒ
- åŸå§‹ CGSV å˜åŒ–
- æ¯è½®æ—¶é—´æ¶ˆè€—

### 2. PCC æ•£ç‚¹å›¾ (`*_pcc_scatter.png`)

- Xè½´ï¼šç‹¬ç«‹è®­ç»ƒå‡†ç¡®ç‡
- Yè½´ï¼šè”é‚¦å­¦ä¹ å‡†ç¡®ç‡
- å¯¹è§’çº¿ï¼šy=xï¼ˆæ— æ”¹è¿›çº¿ï¼‰
- æ‹Ÿåˆçº¿ï¼šçº¿æ€§å›å½’
- æ ‡æ³¨ï¼šPCCå€¼å’Œp-value

### 3. IPR æŸ±çŠ¶å›¾ (`*_ipr_bar.png`)

åŒ…å« 2 ä¸ªå­å›¾ï¼š
- å®¢æˆ·ç«¯æ€§èƒ½æ”¹è¿›ï¼ˆç»¿è‰²=å—ç›Šï¼Œçº¢è‰²=æœªå—ç›Šï¼‰
- ç‹¬ç«‹ vs è”é‚¦å‡†ç¡®ç‡å¯¹æ¯”

### 4. IPR å†å²æ›²çº¿ (`*_ipr_history.png`)

- IPR éšè®­ç»ƒè½®æ¬¡çš„å˜åŒ–
- å¹³å‡ IPR çº¿
- æœ€å 10 è½®å¹³å‡çº¿
- ç›®æ ‡çº¿ï¼ˆ0.95, 0.80ï¼‰

### 5. ä¼šå‘˜ç­‰çº§åˆ†å¸ƒ (`*_membership_distribution.png`)

åŒ…å« 2 ä¸ªå­å›¾ï¼š
- æŸ±çŠ¶å›¾ï¼šå„ç­‰çº§å®¢æˆ·ç«¯æ•°é‡
- é¥¼å›¾ï¼šå„ç­‰çº§ç™¾åˆ†æ¯”

### 6. ç»¼åˆæ‘˜è¦ (`*_comprehensive_summary.png`)

åŒ…å« 7 ä¸ªå­å›¾çš„å®Œæ•´æ€§èƒ½æ€»è§ˆï¼š
- å‡†ç¡®ç‡ç»Ÿè®¡
- IPR æŒ‡æ ‡
- PCC å€¼
- æ€§èƒ½æå‡åˆ†å¸ƒ
- ä¼šå‘˜ç­‰çº§åˆ†å¸ƒ
- æ—¶é—´ç»Ÿè®¡
- å…³é”®æ•°å€¼æ‘˜è¦

---

## ğŸ” ç»“æœè§£è¯»ç¤ºä¾‹

### å®éªŒç»“æœç¤ºä¾‹

```
================================================================================
ğŸ‰ Experiment Completed! / å®éªŒå®Œæˆï¼
================================================================================
Experiment / å®éªŒ: cifar10_non-iid-dir_a0.5_c100_r50_TierConstrained_default_magnitude_20250127_143025

ğŸ“ˆ Key Results / å…³é”®ç»“æœ:
  Methodology / æ–¹æ³•: Tier-Constrained Dynamic Gradient Reward
  Final Avg Accuracy / æœ€ç»ˆå¹³å‡å‡†ç¡®ç‡: 0.6523
  PCC: 0.7845
  IPR: 0.8900 (89.00%)
  Total Time / æ€»è€—æ—¶: 3245.67s

ğŸ“Š PCC Interpretation / PCCè§£è¯»:
  âœ“ Excellent! Strong positive correlation / æå¥½ï¼å¼ºæ­£ç›¸å…³
    æ¿€åŠ±æœºåˆ¶æ•ˆæœæ˜¾è‘—ï¼Œé«˜è´¡çŒ®å®¢æˆ·ç«¯è·å¾—æ›´å¥½æ€§èƒ½
================================================================================
```

### æŒ‡æ ‡è§£è¯»

**PCC = 0.7845**
- âœ… å¼ºæ­£ç›¸å…³ï¼ˆâ‰¥0.75ï¼‰
- è¯´æ˜ï¼šé«˜è´¡çŒ®å®¢æˆ·ç«¯ç¡®å®è·å¾—äº†æ›´å¥½çš„æ€§èƒ½
- æ¿€åŠ±æœºåˆ¶æœ‰æ•ˆ

**IPR = 0.8900 (89%)**
- âœ… è‰¯å¥½ï¼ˆâ‰¥0.80ï¼‰
- è¯´æ˜ï¼š89% çš„å®¢æˆ·ç«¯ä»è”é‚¦å­¦ä¹ ä¸­å—ç›Š
- å…¬å¹³æ€§å¾—åˆ°ä¿éšœ

**Final Avg Accuracy = 0.6523**
- ç›¸æ¯”ç‹¬ç«‹è®­ç»ƒçš„æ€§èƒ½æå‡
- éœ€è¦ç»“åˆå…·ä½“æ•°æ®é›†åŸºçº¿å¯¹æ¯”

---

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•é€‰æ‹©åˆé€‚çš„ `alpha` å€¼ï¼Ÿ

**A**: 
- `alpha = 0.1`ï¼šæåº¦ Non-IIDï¼Œé€‚åˆæµ‹è¯•æç«¯åœºæ™¯
- `alpha = 0.5`ï¼š**æ¨è**ï¼Œä»£è¡¨ç°å®ä¸­å¸¸è§çš„ä¸­ç­‰å¼‚è´¨æ€§
- `alpha = 1.0`ï¼šæ¥è¿‘ IIDï¼Œå·®å¼‚è¾ƒå°

### Q2: PCC å€¼åä½æ€ä¹ˆåŠï¼Ÿ

**A**: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
1. ä½¿ç”¨ `--tier_config aggressive` å¢å¤§å·®å¼‚åŒ–
2. å¢åŠ è®­ç»ƒè½®æ¬¡ `--num_rounds 100`
3. è°ƒæ•´ `--aggregation_scale` å‚æ•°ï¼ˆé»˜è®¤5.0ï¼Œå¯å°è¯•8.0æˆ–10.0ï¼‰
4. ä½¿ç”¨ `--sparsification_mode magnitude` ç¡®ä¿ä¿ç•™é‡è¦å‚æ•°

### Q3: IPR å€¼åä½æ€ä¹ˆåŠï¼Ÿ

**A**: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
1. ä½¿ç”¨ `--tier_config moderate` å‡å°å·®å¼‚åŒ–
2. å¢åŠ ç‹¬ç«‹è®­ç»ƒè½®æ¬¡ `--standalone_epochs 30`
3. å¢åŠ è”é‚¦å­¦ä¹ è½®æ¬¡è®©ä½è´¡çŒ®å®¢æˆ·ç«¯æœ‰æ›´å¤šæ”¹è¿›æœºä¼š
4. è°ƒæ•´ Bronze å±‚çº§çš„æœ€ä½ä¿ç•™ç‡ï¼ˆåœ¨ config.py ä¸­ä¿®æ”¹ï¼‰

### Q4: å†…å­˜ä¸è¶³ (Out of Memory) æ€ä¹ˆåŠï¼Ÿ

**A**:
1. å‡å°‘å®¢æˆ·ç«¯æ•°é‡ï¼š`--num_clients 50`
2. å‡å°æ‰¹æ¬¡å¤§å°ï¼š`--batch_size 16`
3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ SimpleCNN è€Œé ResNetï¼‰
4. ä½¿ç”¨ CPUï¼š`DEVICE = torch.device("cpu")`ï¼ˆåœ¨ config.py ä¸­ï¼‰

### Q5: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**:
1. å‡å°‘å®¢æˆ·ç«¯æ•°é‡
2. å‡å°‘æœ¬åœ°è®­ç»ƒè½®æ¬¡ï¼š`--local_epochs 1`
3. å‡å°‘é€šä¿¡è½®æ¬¡ï¼ˆä½†å¯èƒ½å½±å“æ•ˆæœï¼‰
4. ä½¿ç”¨ GPU åŠ é€Ÿ
5. å‡å°æ•°æ®é›†ï¼ˆå¦‚ç”¨ MNIST ä»£æ›¿ CIFAR-10ï¼‰

### Q6: å¦‚ä½•æ·»åŠ æ–°çš„æ•°æ®é›†ï¼Ÿ

**A**:
1. åœ¨ `datasets/data_loader.py` ä¸­æ·»åŠ æ•°æ®é›†ç±»
2. åœ¨ `config.py` çš„ `DatasetConfig` ä¸­æ·»åŠ é…ç½®
3. åœ¨ `models/cnn_model.py` çš„ `ModelFactory` ä¸­æ·»åŠ å¯¹åº”æ¨¡å‹
4. æ›´æ–° `main.py` çš„å‚æ•°é€‰é¡¹

### Q7: å¦‚ä½•ä¿®æ”¹å±‚çº§ä¿ç•™ç‡èŒƒå›´ï¼Ÿ

**A**: åœ¨ `config.py` ä¸­ä¿®æ”¹ `IncentiveConfig`:

```python
TIER_KEEP_RATIO_RANGES = {
    'gold': (0.90, 1.0),    # è‡ªå®šä¹‰èŒƒå›´
    'silver': (0.60, 0.90),
    'bronze': (0.20, 0.60)
}
```

### Q8: ç»“æœä¿å­˜åœ¨å“ªé‡Œï¼Ÿ

**A**: 
- **JSONç»“æœ**ï¼š`outputs/results/*.json`
- **å¯è§†åŒ–å›¾è¡¨**ï¼š`outputs/figures/*.png`
- **æ—¥å¿—æ–‡ä»¶**ï¼š`outputs/logs/*.log`ï¼ˆå¦‚æœ‰é…ç½®ï¼‰

### Q9: å¦‚ä½•å¤ç°è®ºæ–‡ç»“æœï¼Ÿ

**A**: ä½¿ç”¨ä»¥ä¸‹é…ç½®ï¼š

```bash
python main.py \
    --dataset cifar10 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --num_clients 100 \
    --num_rounds 100 \
    --local_epochs 5 \
    --tier_config default \
    --sparsification_mode magnitude \
    --aggregation_method contribution \
    --seed 42
```

### Q10: GPU æ£€æµ‹å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: è¿è¡Œè¯Šæ–­è„šæœ¬ï¼š

```bash
python gpu_check.py
```

ç„¶åæ ¹æ®è¾“å‡ºä¿¡æ¯ï¼š
- æ£€æŸ¥ CUDA æ˜¯å¦æ­£ç¡®å®‰è£…
- æ£€æŸ¥ PyTorch æ˜¯å¦æ”¯æŒ CUDA
- ç¡®è®¤ GPU é©±åŠ¨ç‰ˆæœ¬å…¼å®¹

---

## ğŸ“š å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

### åŸå§‹è®ºæ–‡

```bibtex
@inproceedings{neurips2021gradient,
  title={Gradient-Driven Rewards to Guarantee Fairness in Collaborative Machine Learning},
  author={Author Names},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}
```

### æœ¬é¡¹ç›®ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

```bibtex
@misc{federated2025tier,
  title={Tier-Constrained Dynamic Gradient Reward for Fair Federated Learning},
  author={Your Name},
  year={2025},
  publisher={GitHub},
  url={https://github.com/yourusername/federated-learning-incentive}
}
```

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ”¹è¿›å»ºè®®ï¼

### è´¡çŒ®æ–¹å¼

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

### é—®é¢˜æŠ¥å‘Š

è¯·ä½¿ç”¨ [Issues](https://github.com/yourusername/federated-learning-incentive/issues) æŠ¥å‘Šï¼š
- Bug åé¦ˆ
- åŠŸèƒ½è¯·æ±‚
- æ–‡æ¡£æ”¹è¿›å»ºè®®

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ‘¥ ä½œè€…ä¸è‡´è°¢

### ä½œè€…
- **Ziqian** - ç ”ç©¶ä¸å®ç°

### è‡´è°¢
- NeurIPS 2021 è®ºæ–‡ä½œè€…æä¾›çš„ç†è®ºåŸºç¡€
- PyTorch å›¢é˜Ÿæä¾›çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- æ‰€æœ‰è´¡çŒ®è€…å’Œä½¿ç”¨è€…

---

## ğŸ“§ è”ç³»æ–¹å¼

- **GitHub**: [@yourusername](https://github.com/yourusername)
- **Email**: your.email@example.com
- **Issues**: [é¡¹ç›® Issues é¡µé¢](https://github.com/yourusername/federated-learning-incentive/issues)

---

## ğŸ”— ç›¸å…³èµ„æº

### è®ºæ–‡ä¸æ–‡æ¡£
- [NeurIPS 2021 åŸå§‹è®ºæ–‡](é“¾æ¥)
- [è”é‚¦å­¦ä¹ ç»¼è¿°](é“¾æ¥)
- [Shapley Value è¯¦è§£](é“¾æ¥)

### ç›¸å…³é¡¹ç›®
- [FedML](https://github.com/FedML-AI/FedML) - è”é‚¦å­¦ä¹ æ¡†æ¶
- [PySyft](https://github.com/OpenMined/PySyft) - éšç§ä¿æŠ¤æœºå™¨å­¦ä¹ 
- [LEAF](https://github.com/TalwalkarLab/leaf) - è”é‚¦å­¦ä¹ åŸºå‡†

### æ•™ç¨‹ä¸åšå®¢
- [è”é‚¦å­¦ä¹ å…¥é—¨æ•™ç¨‹](é“¾æ¥)
- [Non-IID æ•°æ®å¤„ç†](é“¾æ¥)
- [æ¿€åŠ±æœºåˆ¶è®¾è®¡](é“¾æ¥)

---

## ğŸ“ å­¦æœ¯ç ”ç©¶

æœ¬é¡¹ç›®é€‚åˆç”¨äºï¼š
- è”é‚¦å­¦ä¹ æ¿€åŠ±æœºåˆ¶ç ”ç©¶
- Non-IID æ•°æ®å¤„ç†æ–¹æ³•ç ”ç©¶
- å…¬å¹³æ€§ä¿è¯æœºåˆ¶ç ”ç©¶
- è´¡çŒ®åº¦é‡åŒ–æ–¹æ³•ç ”ç©¶

### å¯æ‰©å±•çš„ç ”ç©¶æ–¹å‘

1. **æ–°çš„è´¡çŒ®åº¦åº¦é‡æ–¹æ³•**
   - é™¤äº† CGSVï¼Œæ¢ç´¢å…¶ä»– Shapley Value è¿‘ä¼¼æ–¹æ³•
   - åŸºäºæ¨¡å‹æ€§èƒ½çš„è´¡çŒ®åº¦åº¦é‡

2. **åŠ¨æ€å±‚çº§è°ƒæ•´**
   - è‡ªé€‚åº”çš„å±‚çº§ç™¾åˆ†ä½
   - åŸºäºå†å²è¡¨ç°çš„å±‚çº§å‡é™æœºåˆ¶

3. **éšç§ä¿æŠ¤å¢å¼º**
   - å·®åˆ†éšç§æ¢¯åº¦èšåˆ
   - å®‰å…¨å¤šæ–¹è®¡ç®—

4. **é€šä¿¡æ•ˆç‡ä¼˜åŒ–**
   - æ¢¯åº¦å‹ç¼©æŠ€æœ¯
   - å®¢æˆ·ç«¯é€‰æ‹©ç­–ç•¥

5. **å¼‚æ„è®¾å¤‡æ”¯æŒ**
   - è€ƒè™‘è®¡ç®—èƒ½åŠ›å·®å¼‚
   - è‡ªé€‚åº”çš„æœ¬åœ°è®­ç»ƒè½®æ¬¡

---

<div align="center">

**â­ å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Starï¼â­**

[â¬† å›åˆ°é¡¶éƒ¨](#è”é‚¦å­¦ä¹ å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±æœºåˆ¶)

Made with â¤ï¸ by Ziqian

</div>