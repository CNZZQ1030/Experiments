# åŸºäºç¨€ç–åŒ–çš„è”é‚¦å­¦ä¹ æ¿€åŠ±æœºåˆ¶ / Sparsification-based Federated Learning Incentive Mechanism

## ğŸ“– æ¦‚è¿° / Overview

æœ¬é¡¹ç›®å®ç°äº†ä¸€ç§æ–°é¢–çš„è”é‚¦å­¦ä¹ æ¿€åŠ±æœºåˆ¶ï¼Œä½¿ç”¨**æ¨¡å‹ç¨€ç–åŒ–ï¼ˆå‡æ³•ï¼‰**æ›¿ä»£ä¼ ç»Ÿçš„**é€‰æ‹©æ€§èšåˆï¼ˆåŠ æ³•ï¼‰**æ–¹æ³•ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯æ ¹æ®å®¢æˆ·ç«¯çš„è´¡çŒ®åº¦å¯¹å…¨å±€æ¨¡å‹è¿›è¡Œä¸åŒç¨‹åº¦çš„ç¨€ç–åŒ–å¤„ç†ã€‚

This project implements a novel federated learning incentive mechanism using **model sparsification (subtraction)** instead of traditional **selective aggregation (addition)** methods. The core idea is to apply different levels of sparsification to the global model based on client contributions.

## ğŸ¯ æ ¸å¿ƒåˆ›æ–° / Core Innovation

### ä¼ ç»Ÿæ–¹æ³•ï¼ˆåŠ æ³•ï¼‰vs æ–°æ–¹æ³•ï¼ˆå‡æ³•ï¼‰

**ä¼ ç»Ÿæ–¹æ³• (UPSM - åŠ æ³•ç­–ç•¥):**
- é€‰æ‹©æ€§åœ°èšåˆéƒ¨åˆ†å®¢æˆ·ç«¯çš„æ›´æ–°
- ä½¿ç”¨Boltzmannåˆ†å¸ƒè¿›è¡Œæ¦‚ç‡é‡‡æ ·
- é«˜è´¡çŒ®å®¢æˆ·ç«¯çš„æ›´æ–°è¢«ä¼˜å…ˆé€‰æ‹©

**æ–°æ–¹æ³• (ç¨€ç–åŒ– - å‡æ³•ç­–ç•¥):**
- æ‰€æœ‰å®¢æˆ·ç«¯æ›´æ–°éƒ½å‚ä¸èšåˆï¼ˆä½¿ç”¨FedAvgï¼‰
- å¯¹èšåˆåçš„å…¨å±€æ¨¡å‹è¿›è¡Œå·®å¼‚åŒ–ç¨€ç–å¤„ç†
- é«˜è´¡çŒ®å®¢æˆ·ç«¯è·å¾—æ›´å®Œæ•´çš„æ¨¡å‹ï¼ˆä½ç¨€ç–ç‡ï¼‰
- ä½è´¡çŒ®å®¢æˆ·ç«¯è·å¾—ç¨€ç–åŒ–çš„æ¨¡å‹ï¼ˆé«˜ç¨€ç–ç‡ï¼‰

### ç¨€ç–åŒ–ç®—æ³•è®¾è®¡

#### 1. ä¿ç•™ç‡è®¡ç®— / Keep Ratio Calculation

```
Î±_i = Min_Keep + (1 - Min_Keep) Ã— (r_i)^Î»
```

- `r_i`: å®¢æˆ·ç«¯içš„å½’ä¸€åŒ–è´¡çŒ®æ’å (0åˆ°1)
- `Î»`: è°ƒèŠ‚ç³»æ•°ï¼ˆÎ»>1ä¸ºå‡¸å‡½æ•°ï¼Œè®©é«˜è´¡çŒ®è€…ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼‰
- `Min_Keep`: æœ€ä½ä¿ç•™ç‡ï¼ˆå¦‚0.1ï¼Œå³ä¿ç•™10%å‚æ•°ï¼‰

#### 2. ä¼šå‘˜ç­‰çº§ç¨€ç–ç‡èŒƒå›´ / Membership Level Sparsity Ranges

| ç­‰çº§/Level | è´¡çŒ®åº¦èŒƒå›´/Contribution | ç¨€ç–ç‡èŒƒå›´/Sparsity Range | ä¿ç•™å‚æ•°/Keep Params |
|------------|-------------------------|---------------------------|----------------------|
| Diamond    | Top 10% (r_i > 0.9)     | [0%, 10%]                | 90%-100%            |
| Gold       | Next 30%                | [10%, 30%]               | 70%-90%             |
| Silver     | Next 40%                | [30%, 60%]               | 40%-70%             |
| Bronze     | Bottom 20%              | [60%, 95%]               | 5%-40%              |

## ğŸš€ å¿«é€Ÿå¼€å§‹ / Quick Start

### ç¯å¢ƒè¦æ±‚ / Requirements

```bash
# å®‰è£…ä¾èµ– / Install dependencies
pip install -r requirements.txt
```

### åŸºç¡€å®éªŒ / Basic Experiment

```bash
# MNISTæ•°æ®é›†ï¼ŒIIDåˆ†å¸ƒï¼Œmagnitudeç¨€ç–åŒ–
python main_sparsification.py --dataset mnist --distribution iid

# CIFAR-10æ•°æ®é›†ï¼ŒNon-IIDåˆ†å¸ƒï¼Œç»“æ„åŒ–ç¨€ç–åŒ–
python main_sparsification.py --dataset cifar10 --distribution non-iid-dir \
    --alpha 0.5 --sparsification_mode structured --lambda_coef 2.0
```

### æ‰¹é‡å®éªŒ / Batch Experiments

```bash
# è¿è¡ŒåŸºç¡€å®éªŒå¥—ä»¶
python run_experiments_sparsification.py --experiment basic

# è¿è¡Œå¯¹æ¯”å®éªŒï¼ˆä¸åŒç¨€ç–åŒ–æ¨¡å¼ï¼‰
python run_experiments_sparsification.py --experiment comparison

# è¿è¡Œå®Œæ•´å®éªŒå¥—ä»¶
python run_experiments_sparsification.py --experiment full
```

## ğŸ“ å‘½ä»¤è¡Œå‚æ•° / Command Line Arguments

### åŸºç¡€å‚æ•° / Basic Parameters

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|-----|------|-------|------|
| `--dataset` | str | cifar10 | æ•°æ®é›†: mnist, fashion-mnist, cifar10, cifar100 |
| `--num_clients` | int | 100 | å®¢æˆ·ç«¯æ•°é‡ |
| `--num_rounds` | int | 50 | é€šä¿¡è½®æ¬¡ |
| `--distribution` | str | non-iid-dir | æ•°æ®åˆ†å¸ƒ: iid, non-iid-dir |
| `--alpha` | float | 0.5 | Dirichletåˆ†å¸ƒå‚æ•° (ç”¨äºnon-iid-dir) |

### ç¨€ç–åŒ–å‚æ•° / Sparsification Parameters

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|-----|------|-------|------|
| `--sparsification_mode` | str | magnitude | ç¨€ç–åŒ–æ¨¡å¼: magnitude, random, structured |
| `--lambda_coef` | float | 2.0 | ä¿ç•™ç‡è®¡ç®—çš„Î»ç³»æ•° |
| `--min_keep_ratio` | float | 0.1 | æœ€å°ä¿ç•™ç‡ |

### è®­ç»ƒå‚æ•° / Training Parameters

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|-----|------|-------|------|
| `--local_epochs` | int | 5 | æœ¬åœ°è®­ç»ƒè½®æ¬¡ |
| `--batch_size` | int | 32 | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | 0.01 | å­¦ä¹ ç‡ |
| `--standalone_epochs` | int | 20 | ç‹¬ç«‹è®­ç»ƒè½®æ¬¡ï¼ˆç”¨äºåŸºå‡†ï¼‰ |

## ğŸ”¬ ç¨€ç–åŒ–æ¨¡å¼ / Sparsification Modes

### 1. Magnitude-based (åŸºäºæƒé‡å¤§å°)
- ä¿ç•™æƒé‡ç»å¯¹å€¼æœ€å¤§çš„å‚æ•°
- é€‚åˆä¸€èˆ¬çš„ç¥ç»ç½‘ç»œæ¨¡å‹
- è®¡ç®—æ•ˆç‡é«˜

### 2. Random (éšæœºç¨€ç–åŒ–)
- éšæœºé€‰æ‹©è¦ä¿ç•™çš„å‚æ•°
- ä½œä¸ºåŸºå‡†å¯¹æ¯”æ–¹æ³•
- ä¸è€ƒè™‘å‚æ•°é‡è¦æ€§

### 3. Structured (ç»“æ„åŒ–ç¨€ç–åŒ–)
- æŒ‰æ•´ä¸ªæ»¤æ³¢å™¨/é€šé“è¿›è¡Œç¨€ç–åŒ–
- å¯ä»¥å®ç°å®é™…çš„åŠ é€Ÿæ•ˆæœ
- é€‚åˆå·ç§¯ç¥ç»ç½‘ç»œ

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡ / Evaluation Metrics

### PCC (Pearson Correlation Coefficient)
- è¯„ä¼°ç‹¬ç«‹è®­ç»ƒä¸è”é‚¦å­¦ä¹ æ€§èƒ½çš„ç›¸å…³æ€§
- ç›®æ ‡ï¼šæé«˜PCCå€¼ï¼ˆ>0.6ä¸ºè‰¯å¥½ï¼‰

### IPR (Incentivized Participation Rate)
- æ¿€åŠ±å‚ä¸ç‡ï¼šå—ç›Šå®¢æˆ·ç«¯çš„æ¯”ä¾‹
- å…¬å¼ï¼šIPR = (è·å¾—æ€§èƒ½æå‡çš„å®¢æˆ·ç«¯æ•°) / æ€»å®¢æˆ·ç«¯æ•°
- ç›®æ ‡ï¼šIPR > 0.8

### å®é™…ç¨€ç–ç‡ç»Ÿè®¡
- å„ç­‰çº§å®¢æˆ·ç«¯çš„å¹³å‡ä¿ç•™ç‡
- ç¨€ç–åŒ–çš„å®é™…æ•ˆæœ
- æ¨¡å‹å‹ç¼©æ¯”ä¾‹

## ğŸ“ é¡¹ç›®ç»“æ„ / Project Structure

```
.
â”œâ”€â”€ main_sparsification.py              # ä¸»ç¨‹åº
â”œâ”€â”€ run_experiments_sparsification.py   # å®éªŒè¿è¡Œè„šæœ¬
â”œâ”€â”€ config_updated.py                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ incentive/
â”‚   â”œâ”€â”€ sparsification_distributor.py  # ç¨€ç–åŒ–åˆ†å‘å™¨ï¼ˆæ ¸å¿ƒæ¨¡å—ï¼‰
â”‚   â”œâ”€â”€ membership.py                  # ä¼šå‘˜ç³»ç»Ÿ
â”‚   â”œâ”€â”€ time_slice.py                  # æ—¶é—´ç‰‡ç®¡ç†
â”‚   â””â”€â”€ points_calculator.py           # CGSVè´¡çŒ®åº¦è®¡ç®—
â”œâ”€â”€ federated/
â”‚   â”œâ”€â”€ server_sparsification.py       # è”é‚¦æœåŠ¡å™¨ï¼ˆç¨€ç–åŒ–ç‰ˆæœ¬ï¼‰
â”‚   â””â”€â”€ client.py                      # è”é‚¦å®¢æˆ·ç«¯
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ results/                       # å®éªŒç»“æœJSON
â”‚   â””â”€â”€ figures/                       # å¯è§†åŒ–å›¾è¡¨
â””â”€â”€ README_sparsification.md           # æœ¬æ–‡æ¡£
```

## ğŸ§ª å®éªŒç¤ºä¾‹ / Experiment Examples

### ç¤ºä¾‹1: æµ‹è¯•ä¸åŒÎ»å€¼çš„å½±å“

```bash
# Î»=1 (çº¿æ€§å…³ç³»)
python main_sparsification.py --dataset cifar10 --lambda_coef 1.0

# Î»=2 (å‡¸å‡½æ•°ï¼Œé»˜è®¤)
python main_sparsification.py --dataset cifar10 --lambda_coef 2.0

# Î»=3 (æ›´å‡¸çš„å‡½æ•°ï¼Œé«˜è´¡çŒ®è€…ä¼˜åŠ¿æ›´æ˜æ˜¾)
python main_sparsification.py --dataset cifar10 --lambda_coef 3.0
```

### ç¤ºä¾‹2: å¯¹æ¯”ä¸åŒæ•°æ®åˆ†å¸ƒ

```bash
# IIDåˆ†å¸ƒ
python main_sparsification.py --dataset cifar10 --distribution iid

# Non-IID (Î±=0.5, ä¸­ç­‰å¼‚è´¨æ€§)
python main_sparsification.py --dataset cifar10 --distribution non-iid-dir --alpha 0.5

# Non-IID (Î±=0.1, é«˜åº¦å¼‚è´¨æ€§)
python main_sparsification.py --dataset cifar10 --distribution non-iid-dir --alpha 0.1
```

### ç¤ºä¾‹3: å¤§è§„æ¨¡å®éªŒ

```bash
python main_sparsification.py \
    --dataset cifar100 \
    --num_clients 200 \
    --num_rounds 150 \
    --distribution non-iid-dir \
    --alpha 0.5 \
    --sparsification_mode structured \
    --lambda_coef 2.5 \
    --local_epochs 5 \
    --standalone_epochs 30
```

## ğŸ“ˆ é¢„æœŸæ”¹è¿› / Expected Improvements

ç›¸æ¯”åŸå§‹çš„UPSMæ–¹æ³•ï¼Œç¨€ç–åŒ–æ–¹æ³•é¢„æœŸå¸¦æ¥ä»¥ä¸‹æ”¹è¿›ï¼š

1. **æ›´é«˜çš„PCCå€¼**: é¢„æœŸä»0.4æå‡åˆ°0.6+
2. **æ›´ç¨³å®šçš„æ”¶æ•›**: å‡å°‘å®¢æˆ·ç«¯ä¹‹é—´çš„æ€§èƒ½å·®å¼‚
3. **è®¡ç®—æ•ˆç‡**: ç¨€ç–æ¨¡å‹å‡å°‘å®¢æˆ·ç«¯çš„è®¡ç®—è´Ÿæ‹…
4. **é€šä¿¡æ•ˆç‡**: å¯ä»¥åªä¼ è¾“éé›¶å‚æ•°çš„ä½ç½®å’Œå€¼
5. **å…¬å¹³æ€§æå‡**: ä½è´¡çŒ®å®¢æˆ·ç«¯ä¹Ÿèƒ½è·å¾—åŸºç¡€æ¨¡å‹åŠŸèƒ½

## ğŸ” è°ƒè¯•å’Œä¼˜åŒ– / Debugging and Optimization

### å¦‚æœPCCä»ç„¶è¾ƒä½ï¼š

1. **è°ƒæ•´Î»å€¼**: å°è¯•1.5, 2.0, 2.5, 3.0
2. **ä¿®æ”¹æœ€å°ä¿ç•™ç‡**: å°è¯•0.05, 0.1, 0.15, 0.2
3. **æ”¹å˜ç¨€ç–åŒ–æ¨¡å¼**: ä»magnitudeæ”¹ä¸ºstructured
4. **è°ƒæ•´ä¼šå‘˜ç­‰çº§æ¯”ä¾‹**: ä¿®æ”¹LEVEL_PERCENTILES
5. **å¢åŠ è®­ç»ƒè½®æ¬¡**: ç¡®ä¿æ¨¡å‹å……åˆ†æ”¶æ•›

### ç›‘æ§æŒ‡æ ‡ï¼š

```python
# åœ¨å®éªŒè¿‡ç¨‹ä¸­ä¼šæ‰“å°ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š
- æ¯è½®çš„å¹³å‡å‡†ç¡®ç‡å’Œç¨€ç–åŒ–ç»Ÿè®¡
- å„ä¼šå‘˜ç­‰çº§çš„åˆ†å¸ƒå’Œå¹³å‡ç¨€ç–ç‡
- CGSVè´¡çŒ®åº¦çš„åˆ†å¸ƒ
- PCCå’ŒIPRçš„å˜åŒ–è¶‹åŠ¿
```

## ğŸ“š å‚è€ƒæ–‡çŒ® / References

1. åŸå§‹UPSMæ–¹æ³•: "Unified Probabilistic Sampling Mechanism for Federated Learning"
2. æ¨¡å‹å‰ªæ: "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
3. è”é‚¦å­¦ä¹ æ¿€åŠ±: "Incentive Mechanism Design for Federated Learning"
4. CGSVè´¡çŒ®åº¦: "Cosine Gradient Shapley Value for Contribution Evaluation"

## ğŸ’¡ åˆ›æ–°ç‚¹æ€»ç»“ / Innovation Summary

1. **æ–¹æ³•è®ºåˆ›æ–°**: ä»"åŠ æ³•"ï¼ˆé€‰æ‹©æ€§èšåˆï¼‰è½¬å‘"å‡æ³•"ï¼ˆå·®å¼‚åŒ–ç¨€ç–ï¼‰
2. **åŒé‡æ§åˆ¶**: ç»“åˆä¼šå‘˜ç­‰çº§ï¼ˆç¦»æ•£ï¼‰å’Œè´¡çŒ®åº¦ï¼ˆè¿ç»­ï¼‰è¿›è¡Œç²¾ç»†æ§åˆ¶
3. **å®ç”¨æ€§**: ç¨€ç–åŒ–ä¸ä»…å·®å¼‚åŒ–å¥–åŠ±ï¼Œè¿˜å¸¦æ¥å®é™…çš„è®¡ç®—å’Œé€šä¿¡ä¼˜åŠ¿
4. **å…¬å¹³æ€§**: ä¿è¯æ‰€æœ‰å®¢æˆ·ç«¯éƒ½èƒ½è·å¾—å¯ç”¨çš„æ¨¡å‹ï¼ˆè‡³å°‘10%å‚æ•°ï¼‰

---

**æ³¨æ„ / Note**: æœ¬ä»£ç æ˜¯ç ”ç©¶åŸå‹ï¼Œå®é™…éƒ¨ç½²æ—¶éœ€è¦è€ƒè™‘å®‰å…¨æ€§ã€éšç§ä¿æŠ¤å’Œç³»ç»Ÿé²æ£’æ€§ç­‰å› ç´ ã€‚

**ä½œè€… / Author**: Ziqian (Research on Federated Learning Incentive Mechanisms)