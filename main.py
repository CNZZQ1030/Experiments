"""
main.py - å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±å®éªŒä¸»ç¨‹åºï¼ˆé‡æ„ç‰ˆï¼‰
Main Program - Tier-Constrained Dynamic Gradient Reward Experiment (Refactored)

åŸºäºNeurIPS 2021è®ºæ–‡"Gradient-Driven Rewards to Guarantee Fairness in Collaborative Machine Learning"
Based on NeurIPS 2021 paper "Gradient-Driven Rewards to Guarantee Fairness in Collaborative Machine Learning"

æ ¸å¿ƒåˆ›æ–° / Core Innovations:
1. å±‚çº§ä½œä¸ºç¨€ç–ç‡çš„ä¸Šä¸‹ç•Œï¼ˆBoundsï¼‰/ Tiers as bounds for keep ratios
2. ç»„å†…æ’å€¼ï¼ˆIntra-Tier Interpolationï¼‰/ Intra-tier interpolation
3. å¤§å¹…é™ä½ä½è´¡çŒ®å®¢æˆ·ç«¯çš„å‚æ•°ä¿ç•™ç‡ä»¥æé«˜PCC / Significantly reduce keep ratio for low-contribution clients

ä¿®å¤è¯´æ˜ / Bug Fix:
- ä¿®å¤äº†æ¢¯åº¦è®¡ç®—åŸºå‡†ç‚¹çš„é—®é¢˜
- åœ¨æ­¥éª¤6ä¸­ï¼Œå®¢æˆ·ç«¯åº”ç”¨ç¨€ç–æ¢¯åº¦åï¼Œç«‹å³æ›´æ–°æœåŠ¡å™¨è®°å½•çš„client_previous_weights
- ç¡®ä¿ä¸‹ä¸€è½®æ¢¯åº¦è®¡ç®—ï¼šÎ”w_i = w_i^new - w_local_i^(åº”ç”¨ç¨€ç–æ¢¯åº¦å)

ä½¿ç”¨æ–¹æ³• / Usage:
    # åŸºç¡€å®éªŒ - CIFAR10 + Non-IID
    python main.py --dataset cifar10 --distribution non-iid-dir --alpha 0.5
    
    # ä½¿ç”¨æ¿€è¿›é…ç½®ï¼ˆæ›´å¤§å·®å¼‚åŒ–ï¼‰
    python main.py --dataset cifar10 --tier_config aggressive
    
    # ä½¿ç”¨æ¸©å’Œé…ç½®
    python main.py --dataset cifar10 --tier_config moderate
    
    # å®Œæ•´å‚æ•°ç¤ºä¾‹
    python main.py --dataset cifar10 --distribution non-iid-dir --alpha 0.5 \\
                   --num_clients 100 --num_rounds 100 --tier_config default \\
                   --sparsification_mode magnitude --aggregation_method contribution
"""

import torch
import numpy as np
import random
import argparse
import os
import sys
import time
import json
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„ / Add project path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import FederatedConfig, IncentiveConfig, DatasetConfig, DEVICE
from datasets.data_loader import FederatedDataLoader
from models.cnn_model import ModelFactory
from incentive.time_slice import TimeSliceManager
from incentive.membership import MembershipSystem
from utils.metrics import MetricsCalculator
from utils.visualization import Visualizer

# å¯¼å…¥é‡æ„çš„æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯ / Import refactored server and client
from federated.server import FederatedServerWithGradientSparsification
from federated.client import FederatedClient


def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­ / Set random seed"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


class TierConstrainedFederatedLearning:
    """
    å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±è”é‚¦å­¦ä¹ å®éªŒ
    Tier-Constrained Dynamic Gradient Reward Federated Learning Experiment
    
    æ ¸å¿ƒåˆ›æ–° / Core Innovations:
    1. èšåˆå…¨å±€æ¢¯åº¦è€Œéæ¨¡å‹æƒé‡ / Aggregate global gradients instead of model weights
    2. ä½¿ç”¨å±‚çº§çº¦æŸè¿›è¡Œå·®å¼‚åŒ–ç¨€ç– / Use tier constraints for differential sparsification
    3. ç»„å†…æ’å€¼å®ç°è¿ç»­æ˜ å°„ / Intra-tier interpolation for continuous mapping
    4. åŸºäºå¹…åº¦çš„ç¨€ç–åŒ–ä¿ç•™æœ€é‡è¦å‚æ•° / Magnitude-based pruning to retain important parameters
    
    æ­£ç¡®çš„è®­ç»ƒæµç¨‹ / Correct Training Workflow:
    1. å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼šw_i^t = LocalTrain(w_local_i^(t-1))
    2. æœåŠ¡å™¨è®¡ç®—æ¢¯åº¦ï¼šÎ”w_i = w_i^t - w_local_i^(t-1)
    3. èšåˆå…¨å±€æ¢¯åº¦ï¼šÎ”w_global = Aggregate(Î”w_i)
    4. ç¨€ç–åŒ–åˆ†å‘ï¼šsparse_i(Î”w_global)
    5. å®¢æˆ·ç«¯åº”ç”¨ï¼šw_local_i^t = w_i^t + lr * sparse_i(Î”w_global)
    6. æ›´æ–°åŸºå‡†ç‚¹ï¼šclient_previous_weights[i] = w_local_i^t
    """
    
    def __init__(self, args):
        """åˆå§‹åŒ–å®éªŒ / Initialize experiment"""
        self.args = args
        set_seed(args.seed)
        
        self.device = DEVICE
        self.experiment_name = self._generate_experiment_name()
        
        print(f"\n{'='*80}")
        print(f"Tier-Constrained Dynamic Gradient Reward Federated Learning")
        print(f"å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±è”é‚¦å­¦ä¹ ")
        print(f"{'='*80}")
        print(f"Experiment / å®éªŒåç§°: {self.experiment_name}")
        print(f"Dataset / æ•°æ®é›†: {args.dataset}")
        print(f"Distribution / åˆ†å¸ƒ: {args.distribution}")
        if args.distribution == "non-iid-dir":
            print(f"  Alpha: {args.alpha}")
        print(f"Clients / å®¢æˆ·ç«¯æ•°: {args.num_clients}")
        print(f"Rounds / è½®æ¬¡: {args.num_rounds}")
        print(f"Device / è®¾å¤‡: {self.device}")
        
        print(f"\nâœ¨ Tier-Constrained Configuration / å±‚çº§çº¦æŸé…ç½®:")
        print(f"  Tier Config / å±‚çº§é…ç½®: {args.tier_config}")
        print(f"  Sparsification Mode / ç¨€ç–åŒ–æ¨¡å¼: {args.sparsification_mode}")
        print(f"  Aggregation Method / èšåˆæ–¹å¼: {args.aggregation_method}")
        print(f"  Gradient Application LR / æ¢¯åº¦åº”ç”¨å­¦ä¹ ç‡: {args.gradient_lr}")
        
        # æ˜¾ç¤ºå±‚çº§ä¿ç•™ç‡èŒƒå›´ / Show tier keep ratio ranges
        if args.tier_config == "aggressive":
            tier_ranges = IncentiveConfig.TIER_KEEP_RATIO_RANGES_AGGRESSIVE
        elif args.tier_config == "moderate":
            tier_ranges = IncentiveConfig.TIER_KEEP_RATIO_RANGES_MODERATE
        else:
            tier_ranges = IncentiveConfig.TIER_KEEP_RATIO_RANGES
        
        print(f"\nğŸ“Š Tier Keep Ratio Ranges / å±‚çº§ä¿ç•™ç‡èŒƒå›´:")
        for tier, (low, high) in tier_ranges.items():
            sparsity_low, sparsity_high = 1.0 - high, 1.0 - low
            print(f"    {tier.capitalize():8s}: Keep [{low:.2f}, {high:.2f}] "
                  f"(Sparsity [{sparsity_low:.2f}, {sparsity_high:.2f}])")
        print(f"{'='*80}")
        
        # æ›´æ–°é…ç½® / Update configuration
        IncentiveConfig.SPARSIFICATION_MODE = args.sparsification_mode
        
        self._initialize_components()
    
    def _generate_experiment_name(self) -> str:
        """ç”Ÿæˆå®éªŒåç§° / Generate experiment name"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        dist_suffix = f"_a{self.args.alpha}" if self.args.distribution == "non-iid-dir" else ""
        tier_suffix = f"_TierConstrained_{self.args.tier_config}_{self.args.sparsification_mode}"
        return f"{self.args.dataset}_{self.args.distribution}{dist_suffix}" \
               f"_c{self.args.num_clients}_r{self.args.num_rounds}{tier_suffix}_{timestamp}"
    
    def _initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ / Initialize all components"""
        print("\nInitializing components / åˆå§‹åŒ–ç»„ä»¶...")
        
        # 1. æ•°æ®åŠ è½½ / Data loading
        print("  [1/6] Loading data / åŠ è½½æ•°æ®...")
        self.data_loader = FederatedDataLoader(
            dataset_name=self.args.dataset,
            num_clients=self.args.num_clients,
            batch_size=self.args.batch_size,
            distribution=self.args.distribution,
            alpha=self.args.alpha
        )
        
        # 2. æ¨¡å‹åˆ›å»º / Model creation
        print("  [2/6] Creating model / åˆ›å»ºæ¨¡å‹...")
        num_classes = DatasetConfig.NUM_CLASSES[self.args.dataset]
    
        # åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡æœ¬æ•°æ®é›† / Check if it's a text dataset
        if DatasetConfig.is_text_dataset(self.args.dataset):
            # ===== æ–‡æœ¬æ•°æ®é›†å¤„ç† / Text dataset handling =====
            vocab_size = self.data_loader.get_vocab_size()
            text_config = DatasetConfig.get_text_config(self.args.dataset)
        
            # åˆ›å»ºæ–‡æœ¬æ¨¡å‹ / Create text model
            self.model = ModelFactory.create_model(
                self.args.dataset,
                num_classes=num_classes,
                vocab_size=vocab_size,
                **text_config
            )
            print(f"     Text model created with vocab_size={vocab_size}")
        else:
            # ===== å›¾åƒæ•°æ®é›†å¤„ç† / Image dataset handling =====
            input_channels = DatasetConfig.INPUT_SHAPE[self.args.dataset][0]
        
            # åˆ›å»ºå›¾åƒæ¨¡å‹ / Create image model
            self.model = ModelFactory.create_model(
                self.args.dataset,
                num_classes=num_classes,
                input_channels=input_channels
            )
    
        # æ‰“å°æ¨¡å‹ä¿¡æ¯ / Print model info
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f" Model parameters / æ¨¡å‹å‚æ•°æ•°: {total_params:,}")
        
        # 3. æœåŠ¡å™¨åˆå§‹åŒ–ï¼ˆå±‚çº§çº¦æŸç‰ˆæœ¬ï¼‰/ Server initialization (tier-constrained version)
        print("  [3/6] Initializing server with Tier-Constrained Gradient Sparsification...")
        print("  åˆå§‹åŒ–å±‚çº§çº¦æŸæ¢¯åº¦ç¨€ç–åŒ–æœåŠ¡å™¨...")
        self.server = FederatedServerWithGradientSparsification(
            model=self.model, 
            device=self.device,
            tier_config=self.args.tier_config,
            aggregation_method=self.args.aggregation_method
        )
        
        # 4. å®¢æˆ·ç«¯åˆ›å»º / Client creation
        print("  [4/6] Creating clients / åˆ›å»ºå®¢æˆ·ç«¯...")
        self.clients = {}
        for client_id in tqdm(range(self.args.num_clients), desc="    Creating", leave=False):
            train_loader = self.data_loader.get_client_train_dataloader(client_id)
            test_loader = self.data_loader.get_client_test_dataloader(client_id)
            num_train = self.data_loader.get_num_train_samples(client_id)
            num_test = self.data_loader.get_num_test_samples(client_id)
            
            client = FederatedClient(
                client_id=client_id,
                model=self.model,
                train_dataloader=train_loader,
                test_dataloader=test_loader,
                num_train_samples=num_train,
                num_test_samples=num_test,
                device=self.device
            )
            self.clients[client_id] = client
        
        # 5. æ¿€åŠ±ç³»ç»Ÿ / Incentive system
        print("  [5/6] Initializing incentive system / åˆå§‹åŒ–æ¿€åŠ±ç³»ç»Ÿ...")
        self.time_slice_manager = TimeSliceManager(
            slice_type="rounds",
            rounds_per_slice=self.args.rounds_per_slice,
            validity_slices=IncentiveConfig.POINTS_VALIDITY_SLICES
        )
        
        # ä½¿ç”¨ä¸‰çº§åˆ¶ä¼šå‘˜ç³»ç»Ÿ / Use three-tier membership system
        self.membership_system = MembershipSystem(
            ranking_percentiles=IncentiveConfig.LEVEL_PERCENTILES,
            use_three_tier=True
        )
        
        for client_id in range(self.args.num_clients):
            self.membership_system.initialize_client(client_id)
        
        # 6. æŒ‡æ ‡ç³»ç»Ÿ / Metrics system
        print("  [6/6] Initializing metrics / åˆå§‹åŒ–æŒ‡æ ‡...")
        self.metrics_calculator = MetricsCalculator()
        self.visualizer = Visualizer(output_dir="outputs/figures")
        
        print("âœ“ All components initialized / æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def compute_standalone_baselines(self):
        """è®¡ç®—ç‹¬ç«‹è®­ç»ƒåŸºå‡† / Compute standalone baselines"""
        print(f"\n{'='*80}")
        print(f"Computing Standalone Baselines ({self.args.standalone_epochs} epochs)")
        print(f"è®¡ç®—ç‹¬ç«‹è®­ç»ƒåŸºå‡†")
        print(f"{'='*80}")
        
        for client_id, client in tqdm(self.clients.items(), desc="Standalone training"):
            standalone_acc, _ = client.train_standalone(epochs=self.args.standalone_epochs)
            self.metrics_calculator.record_standalone_accuracy(client_id, standalone_acc)
        
        # æ‰“å°åŸºå‡†ç»Ÿè®¡ / Print baseline statistics
        standalone_accs = list(self.metrics_calculator.standalone_accuracies.values())
        print(f"\nStandalone Baseline Statistics / ç‹¬ç«‹è®­ç»ƒåŸºå‡†ç»Ÿè®¡:")
        print(f"  Mean / å‡å€¼: {np.mean(standalone_accs):.4f}")
        print(f"  Std / æ ‡å‡†å·®: {np.std(standalone_accs):.4f}")
        print(f"  Range / èŒƒå›´: [{np.min(standalone_accs):.4f}, {np.max(standalone_accs):.4f}]")
        print("âœ“ Standalone baselines computed / ç‹¬ç«‹è®­ç»ƒåŸºå‡†è®¡ç®—å®Œæˆ")
    
    def run_single_round(self, round_num: int) -> dict:
        """
        è¿è¡Œå•è½®è®­ç»ƒ - å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±ç‰ˆæœ¬
        Run single round - Tier-Constrained Dynamic Gradient Reward version
        
        æ ¸å¿ƒæµç¨‹ / Core Workflow:
        1. å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼Œä¸Šä¼ è®­ç»ƒåçš„æƒé‡
        2. æœåŠ¡å™¨è®¡ç®—å®¢æˆ·ç«¯æ¢¯åº¦ï¼šÎ”w_i = w_i^new - w_i^old
        3. èšåˆå…¨å±€æ¢¯åº¦ï¼ˆå¯é€‰è´¡çŒ®åº¦åŠ æƒï¼‰
        4. è®¡ç®—CGSVè´¡çŒ®åº¦å’Œæ›´æ–°ä¼šå‘˜ç­‰çº§
        5. ä½¿ç”¨å±‚çº§çº¦æŸè¿›è¡Œå·®å¼‚åŒ–ç¨€ç–ï¼ˆç»„å†…æ’å€¼ï¼‰
        6. å®¢æˆ·ç«¯åº”ç”¨ç¨€ç–æ¢¯åº¦ï¼Œå¹¶æ›´æ–°æœåŠ¡å™¨è®°å½•çš„åŸºå‡†ç‚¹
        """
        round_start = time.time()
        
        selected_clients = list(range(self.args.num_clients))
        self.server.reset_round()
        client_accuracies = {}
        
        # åˆ¤æ–­æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ / Determine whether to show details
        show_details = (round_num % max(1, self.args.num_rounds // 10) == 0) or \
                      round_num == 1 or round_num == self.args.num_rounds
        
        if show_details:
            print(f"\n{'='*80}")
            print(f"Round {round_num}/{self.args.num_rounds}")
            print(f"{'='*80}")
        
        # ========== æ­¥éª¤1: å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ ==========
        # ========== Step 1: Client local training ==========
        for client_id in tqdm(selected_clients, 
                            desc=f"Round {round_num} - Training",
                            leave=False):
            client = self.clients[client_id]
            
            # ç¬¬ä¸€è½®éœ€è¦åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹ / First round needs to initialize local model
            if round_num == 1:
                global_weights = self.server.get_global_model_weights()
            else:
                global_weights = None  # åç»­è½®æ¬¡ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            
            # æœ¬åœ°è®­ç»ƒ / Local training
            updated_weights, train_info = client.train_federated(
                global_weights=global_weights,
                epochs=self.args.local_epochs,
                lr=self.args.learning_rate
            )
            
            # æœåŠ¡å™¨æ”¶é›†æ›´æ–° / Server collects updates
            self.server.collect_client_updates(client_id, updated_weights, train_info)
            
            # è®°å½•å‡†ç¡®ç‡ / Record accuracy
            federated_acc = train_info['federated_accuracy']
            self.metrics_calculator.record_federated_accuracy(client_id, federated_acc)
            client_accuracies[client_id] = federated_acc
        
        # ========== æ­¥éª¤2: èšåˆå…¨å±€æ¢¯åº¦ ==========
        # ========== Step 2: Aggregate global gradient ==========
        self.server.update_global_model()
        
        # ========== æ­¥éª¤3: è®¡ç®—CGSVè´¡çŒ®åº¦ ==========
        # ========== Step 3: Calculate CGSV contributions ==========
        contributions = self.server.calculate_all_contributions(round_num)
        
        # ========== æ­¥éª¤4: æ—¶é—´ç‰‡ç§¯åˆ†å’Œä¼šå‘˜ç­‰çº§ ==========
        # ========== Step 4: Time slice points and membership levels ==========
        all_active_points = {}
        for client_id, contribution in contributions.items():
            active_points = self.time_slice_manager.add_contribution_points(
                client_id, round_num, contribution
            )
            all_active_points[client_id] = active_points
            
            # æ›´æ–°è´¡çŒ®å†å² / Update contribution history
            self.membership_system.update_contribution_history(client_id, contribution, round_num)
        
        # æ›´æ–°ä¼šå‘˜ç­‰çº§ / Update membership levels
        new_levels = self.membership_system.update_all_memberships_by_ranking(all_active_points)
        for client_id, new_level in new_levels.items():
            self.clients[client_id].update_membership_level(new_level)
        
        # æ¸…ç†è¿‡æœŸç§¯åˆ† / Clean expired points
        current_slice = self.time_slice_manager.get_current_slice(round_num)
        if round_num > 1:
            prev_slice = self.time_slice_manager.get_current_slice(round_num - 1)
            if current_slice != prev_slice:
                cleaned = self.time_slice_manager.clean_expired_points(round_num)
                if cleaned and show_details:
                    print(f"  Time slice changed / æ—¶é—´ç‰‡å˜åŒ–: {prev_slice} â†’ {current_slice}")
                
                # é‡æ–°è®¡ç®—ç­‰çº§ / Recalculate levels
                updated_points = self.time_slice_manager.get_all_client_active_points(round_num)
                new_levels = self.membership_system.update_all_memberships_by_ranking(updated_points)
                for client_id, new_level in new_levels.items():
                    self.clients[client_id].update_membership_level(new_level)
        
        # ========== æ­¥éª¤5: åˆ†å‘å±‚çº§çº¦æŸç¨€ç–åŒ–æ¢¯åº¦ ==========
        # ========== Step 5: Distribute tier-constrained sparsified gradients ==========
        sparsified_gradients = self.server.distribute_sparsified_gradients(new_levels)
        
        # ========== æ­¥éª¤6: å®¢æˆ·ç«¯åº”ç”¨ç¨€ç–æ¢¯åº¦ ==========
        # ========== Step 6: Clients apply sparse gradients ==========
        for client_id in tqdm(selected_clients, 
                            desc=f"Round {round_num} - Applying gradients",
                            leave=False):
            if client_id in sparsified_gradients:
                sparse_gradient = sparsified_gradients[client_id]
                self.clients[client_id].apply_gradient_update(
                    sparse_gradient, 
                    learning_rate=self.args.gradient_lr
                )
                
                # å…³é”®ï¼šæ›´æ–°æœåŠ¡å™¨ç«¯è®°å½•çš„å®¢æˆ·ç«¯"ä¸Šä¸€è½®"æƒé‡
                # CRITICAL: Update server's record of client's "previous round" weights
                # è¿™ç¡®ä¿ä¸‹ä¸€è½®æ¢¯åº¦è®¡ç®—çš„åŸºå‡†ç‚¹æ˜¯æ­£ç¡®çš„ï¼ˆåº”ç”¨ç¨€ç–æ¢¯åº¦åçš„çŠ¶æ€ï¼‰
                # This ensures the gradient baseline for next round is correct
                # (state after applying sparse gradient)
                current_weights = self.clients[client_id].get_local_model_weights()
                self.server.update_client_previous_weights(client_id, current_weights)
        
        round_time = time.time() - round_start
        
        # æ‰“å°è½®æ¬¡æ‘˜è¦ / Print round summary
        if show_details:
            round_summary = self.server.get_round_summary(round_num)
            
            if client_accuracies:
                accs = list(client_accuracies.values())
                print(f"\nğŸ“Š Performance / æ€§èƒ½:")
                print(f"  Avg Accuracy / å¹³å‡å‡†ç¡®ç‡: {np.mean(accs):.4f}")
                print(f"  Max Accuracy / æœ€å¤§å‡†ç¡®ç‡: {np.max(accs):.4f}")
                print(f"  Min Accuracy / æœ€å°å‡†ç¡®ç‡: {np.min(accs):.4f}")
            
            print(f"\nğŸ¯ Contributions (CGSV) / è´¡çŒ®åº¦:")
            contrib_stats = round_summary['contribution_stats']
            print(f"  Mean / å‡å€¼: {contrib_stats['mean']:.4f}, Std / æ ‡å‡†å·®: {contrib_stats['std']:.4f}")
            print(f"  Range / èŒƒå›´: [{contrib_stats['min']:.4f}, {contrib_stats['max']:.4f}]")
            
            # æ‰“å°ç¨€ç–åŒ–ç»Ÿè®¡ / Print sparsification statistics
            if 'sparsification_stats' in round_summary and round_summary['sparsification_stats']:
                sparse_stats = round_summary['sparsification_stats']
                if 'by_level' in sparse_stats:
                    print(f"\nâœ‚ï¸  Tier-Constrained Sparsification / å±‚çº§çº¦æŸç¨€ç–åŒ–:")
                    for level in ['gold', 'silver', 'bronze']:
                        if level in sparse_stats['by_level']:
                            ls = sparse_stats['by_level'][level]
                            print(f"  {level.capitalize():8s}: Keep={ls['mean']:.3f}, "
                                  f"Range=[{ls['min']:.3f}, {ls['max']:.3f}] (n={ls['count']})")
            
            print(f"\nâ±ï¸  Time / è€—æ—¶: {round_time:.2f}s")
            
            # å®šæœŸæ‰“å°ä¼šå‘˜åˆ†å¸ƒ / Periodically print membership distribution
            if round_num % 10 == 0 or round_num == self.args.num_rounds:
                self.membership_system.print_membership_distribution()
        
        # è®°å½•æŒ‡æ ‡ / Record metrics
        round_metrics = {
            'round': round_num,
            'time_consumption': round_time,
            'num_selected_clients': len(selected_clients),
            'contributions': contributions.copy(),
            'client_accuracies': client_accuracies.copy(),
            'current_slice': current_slice,
            'active_points': all_active_points.copy(),
            'membership_levels': new_levels.copy(),
            'sparsification_stats': self.server.sparsification_distributor.get_sparsification_statistics()
        }
        
        self.metrics_calculator.record_round(round_metrics)
        return round_metrics
    
    def run_experiment(self):
        """è¿è¡Œå®Œæ•´å®éªŒ / Run complete experiment"""
        print(f"\n{'='*80}")
        print(f"Starting Experiment / å¼€å§‹å®éªŒ: {self.experiment_name}")
        print(f"{'='*80}")
        
        # ç‹¬ç«‹è®­ç»ƒåŸºå‡† / Standalone baselines
        self.compute_standalone_baselines()
        
        # è”é‚¦å­¦ä¹ è®­ç»ƒ / Federated learning training
        print(f"\n{'='*80}")
        print("Federated Learning with Tier-Constrained Dynamic Gradient Reward")
        print("å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±è”é‚¦å­¦ä¹ ")
        print(f"{'='*80}")
        
        for round_num in range(1, self.args.num_rounds + 1):
            self.run_single_round(round_num)
        
        print(f"\n{'='*80}")
        print("Training Complete / è®­ç»ƒå®Œæˆ")
        print(f"{'='*80}")
        
        # æœ€ç»ˆæŒ‡æ ‡ / Final metrics
        final_metrics = self.metrics_calculator.calculate_final_metrics()
        
        # æ‰“å°æ‘˜è¦ / Print summaries
        self.metrics_calculator.print_summary()
        self.time_slice_manager.print_summary(self.args.num_rounds)
        self.server.print_contribution_summary()
        self.server.print_sparsification_summary()
        self.membership_system.print_membership_distribution()
        
        # ç”Ÿæˆå¯è§†åŒ– / Generate visualizations
        self._generate_visualizations(final_metrics)
        
        # ä¿å­˜ç»“æœ / Save results
        self._save_results(final_metrics)
        
        return final_metrics
    
    def _generate_visualizations(self, final_metrics):
        """ç”Ÿæˆå¯è§†åŒ– / Generate visualizations"""
        print(f"\n{'='*80}")
        print("Generating Visualizations / ç”Ÿæˆå¯è§†åŒ–")
        print(f"{'='*80}")
        
        contributions_history = [rm.get('contributions', {}) 
                                for rm in self.metrics_calculator.round_metrics]
        
        metrics_history = {
            'rounds': list(range(1, len(self.metrics_calculator.avg_client_accuracies) + 1)),
            'avg_client_accuracy': self.metrics_calculator.avg_client_accuracies,
            'max_client_accuracy': self.metrics_calculator.max_client_accuracies,
            'time_per_round': self.metrics_calculator.time_consumptions,
            'contributions': contributions_history,
            'raw_contributions': contributions_history
        }
        
        self.visualizer.generate_all_plots(final_metrics, metrics_history, self.experiment_name)
        print("âœ“ Visualizations generated / å¯è§†åŒ–ç”Ÿæˆå®Œæˆ")
    
    def _save_results(self, final_metrics):
        """ä¿å­˜ç»“æœ / Save results"""
        results_dir = "outputs/results"
        os.makedirs(results_dir, exist_ok=True)
        
        results_path = os.path.join(results_dir, f"{self.experiment_name}_results.json")
        
        # è·å–å±‚çº§é…ç½® / Get tier configuration
        if self.args.tier_config == "aggressive":
            tier_ranges = IncentiveConfig.TIER_KEEP_RATIO_RANGES_AGGRESSIVE
        elif self.args.tier_config == "moderate":
            tier_ranges = IncentiveConfig.TIER_KEEP_RATIO_RANGES_MODERATE
        else:
            tier_ranges = IncentiveConfig.TIER_KEEP_RATIO_RANGES
        
        save_data = {
            'experiment_name': self.experiment_name,
            'methodology': 'Tier-Constrained Dynamic Gradient Reward',
            'methodology_cn': 'å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±',
            'reference': 'NeurIPS 2021 - Gradient-Driven Rewards to Guarantee Fairness in Collaborative Machine Learning',
            'configuration': {
                'dataset': self.args.dataset,
                'num_clients': self.args.num_clients,
                'num_rounds': self.args.num_rounds,
                'distribution': self.args.distribution,
                'alpha': self.args.alpha,
                'rounds_per_slice': self.args.rounds_per_slice,
                'local_epochs': self.args.local_epochs,
                'batch_size': self.args.batch_size,
                'learning_rate': self.args.learning_rate,
                'gradient_lr': self.args.gradient_lr,
                'standalone_epochs': self.args.standalone_epochs,
                'seed': self.args.seed
            },
            'tier_constrained_config': {
                'tier_config': self.args.tier_config,
                'sparsification_mode': self.args.sparsification_mode,
                'aggregation_method': self.args.aggregation_method,
                'tier_keep_ratio_ranges': {k: list(v) for k, v in tier_ranges.items()},
                'level_percentiles': IncentiveConfig.LEVEL_PERCENTILES
            },
            'final_metrics': final_metrics,
            'round_metrics_last_10': self.metrics_calculator.round_metrics[-10:],
            'membership_statistics': self.membership_system.get_membership_statistics(),
            'contribution_statistics': self.server.get_contribution_statistics(),
            'sparsification_statistics': self.server.sparsification_distributor.get_sparsification_statistics()
        }
        
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, indent=2, default=str, ensure_ascii=False)
        
        print(f"âœ“ Results saved to / ç»“æœå·²ä¿å­˜è‡³: {results_path}")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•° / Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description='Tier-Constrained Dynamic Gradient Reward Federated Learning\n'
                    'å±‚çº§çº¦æŸåŠ¨æ€æ¢¯åº¦å¥–åŠ±è”é‚¦å­¦ä¹ ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples / ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€å®éªŒ - MNIST + IID
  python main.py --dataset mnist --distribution iid
  
  # Non-IIDå®éªŒ - CIFAR10ï¼ˆé»˜è®¤é…ç½®ï¼‰
  python main.py --dataset cifar10 --distribution non-iid-dir --alpha 0.5
  
  # ä½¿ç”¨æ¿€è¿›é…ç½®ï¼ˆæ›´å¤§å·®å¼‚åŒ–ï¼Œé€‚åˆæé«˜PCCï¼‰
  python main.py --dataset cifar10 --tier_config aggressive
  
  # ä½¿ç”¨æ¸©å’Œé…ç½®ï¼ˆæ›´å‡è¡¡çš„å·®å¼‚åŒ–ï¼‰
  python main.py --dataset cifar10 --tier_config moderate
  
  # å¤§è§„æ¨¡å®éªŒ
  python main.py --dataset cifar10 --num_clients 100 --num_rounds 100 \\
                 --tier_config default --sparsification_mode magnitude
                 
  # å¯¹æ¯”å®éªŒ - ä½¿ç”¨FedAvgèšåˆ
  python main.py --dataset cifar10 --aggregation_method fedavg
        """
    )
    
    # æ•°æ®é›†å‚æ•° / Dataset parameters
    parser.add_argument('--dataset', type=str, default='cifar10',
                       choices=['mnist', 'fashion-mnist', 'cifar10', 'cifar100', 'mr', 'sst'],
                       help='Dataset name / æ•°æ®é›†åç§°\n'
                            '  Image: mnist, fashion-mnist, cifar10, cifar100\n'
                            '  Text: mr (Movie Review), sst (Stanford Sentiment Treebank)')
    
    parser.add_argument('--num_clients', type=int, default=100,
                       help='Number of clients / å®¢æˆ·ç«¯æ•°é‡')
    
    # æ•°æ®åˆ†å¸ƒ / Data distribution
    parser.add_argument('--distribution', type=str, default='non-iid-dir',
                       choices=['iid', 'non-iid-dir'],
                       help='Data distribution type / æ•°æ®åˆ†å¸ƒç±»å‹')
    
    parser.add_argument('--alpha', type=float, default=0.5,
                       help='Dirichlet alpha for non-iid / Non-IIDçš„Dirichletå‚æ•°')
    
    # è®­ç»ƒå‚æ•° / Training parameters
    parser.add_argument('--num_rounds', type=int, default=50,
                       help='Number of communication rounds / é€šä¿¡è½®æ¬¡')
    
    parser.add_argument('--local_epochs', type=int, default=5,
                       help='Local epochs per round / æ¯è½®æœ¬åœ°è®­ç»ƒè½®æ¬¡')
    
    parser.add_argument('--batch_size', type=int, default=32,
                       help='Batch size / æ‰¹æ¬¡å¤§å°')
    
    parser.add_argument('--learning_rate', type=float, default=0.01,
                       help='Learning rate for local training / æœ¬åœ°è®­ç»ƒå­¦ä¹ ç‡')
    
    parser.add_argument('--gradient_lr', type=float, default=1.0,
                       help='Learning rate for applying sparse gradients / ç¨€ç–æ¢¯åº¦åº”ç”¨å­¦ä¹ ç‡ï¼ˆå…¶å®ä¸è¯¥å«å­¦ä¹ ç‡ï¼Œå°±æ˜¯ä¸€ä¸ªæƒé‡ç³»æ•°ï¼‰')
    
    parser.add_argument('--standalone_epochs', type=int, default=20,
                       help='Standalone training epochs / ç‹¬ç«‹è®­ç»ƒè½®æ¬¡')
    
    # æ—¶é—´ç‰‡å‚æ•° / Time slice parameters
    parser.add_argument('--rounds_per_slice', type=int, default=5,
                       help='Rounds per time slice / æ¯ä¸ªæ—¶é—´ç‰‡çš„è½®æ¬¡')
    
    # å±‚çº§çº¦æŸå‚æ•° / Tier-constrained parameters
    parser.add_argument('--tier_config', type=str, default='default',
                       choices=['default', 'aggressive', 'moderate'],
                       help='Tier configuration / å±‚çº§é…ç½®\n'
                            '  default: Gold[0.8,1.0], Silver[0.5,0.8], Bronze[0.1,0.5]\n'
                            '  aggressive: æ›´å¤§å·®å¼‚åŒ– / More differentiation\n'
                            '  moderate: æ›´æ¸©å’Œ / More moderate')
    
    parser.add_argument('--sparsification_mode', type=str, default='magnitude',
                       choices=['magnitude', 'random', 'structured'],
                       help='Sparsification mode / ç¨€ç–åŒ–æ¨¡å¼\n'
                            '  magnitude: åŸºäºå¹…åº¦ï¼ˆæ¨èï¼‰\n'
                            '  random: éšæœº\n'
                            '  structured: ç»“æ„åŒ–')
    
    parser.add_argument('--aggregation_method', type=str, default='contribution',
                       choices=['fedavg', 'contribution'],
                       help='Aggregation method / èšåˆæ–¹å¼\n'
                            '  fedavg: åŸºäºæ ·æœ¬æ•°é‡\n'
                            '  contribution: åŸºäºè´¡çŒ®åº¦')
    
    # å…¶ä»–å‚æ•° / Other parameters
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed / éšæœºç§å­')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•° / Main function"""
    args = parse_args()
    
    # è¿è¡Œå®éªŒ / Run experiment
    experiment = TierConstrainedFederatedLearning(args)
    final_metrics = experiment.run_experiment()
    
    # æ‰“å°æœ€ç»ˆç»“æœ / Print final results
    print(f"\n{'='*80}")
    print("ğŸ‰ Experiment Completed! / å®éªŒå®Œæˆï¼")
    print(f"{'='*80}")
    print(f"Experiment / å®éªŒ: {experiment.experiment_name}")
    print(f"\nğŸ“ˆ Key Results / å…³é”®ç»“æœ:")
    print(f"  Methodology / æ–¹æ³•: Tier-Constrained Dynamic Gradient Reward")
    print(f"  Final Avg Accuracy / æœ€ç»ˆå¹³å‡å‡†ç¡®ç‡: {final_metrics['client_accuracy']['avg_final']:.4f}")
    print(f"  PCC: {final_metrics['pcc']:.4f}")
    print(f"  IPR: {final_metrics['ipr']['final_ipr']:.4f} ({final_metrics['ipr']['ipr_percentage']:.2f}%)")
    print(f"  Total Time / æ€»è€—æ—¶: {final_metrics['time_consumption']['total']:.2f}s")
    
    # PCCç»“æœè§£è¯» / PCC result interpretation
    pcc = final_metrics['pcc']
    print(f"\nğŸ“Š PCC Interpretation / PCCè§£è¯»:")
    if pcc >= 0.75:
        print(f"  âœ“ Excellent! Strong positive correlation / æå¥½ï¼å¼ºæ­£ç›¸å…³")
        print(f"    æ¿€åŠ±æœºåˆ¶æ•ˆæœæ˜¾è‘—ï¼Œé«˜è´¡çŒ®å®¢æˆ·ç«¯è·å¾—æ›´å¥½æ€§èƒ½")
    elif pcc >= 0.65:
        print(f"  âœ“ Good! Moderate positive correlation / è‰¯å¥½ï¼ä¸­ç­‰æ­£ç›¸å…³")
        print(f"    æ¿€åŠ±æœºåˆ¶æœ‰æ•ˆï¼Œè´¡çŒ®ä¸æ”¶ç›Šå‘ˆæ­£ç›¸å…³")
    elif pcc >= 0.5:
        print(f"  â–³ Fair. Weak positive correlation / ä¸€èˆ¬ã€‚å¼±æ­£ç›¸å…³")
        print(f"    æ¿€åŠ±æœºåˆ¶æœ‰ä¸€å®šæ•ˆæœï¼Œå¯è€ƒè™‘ä½¿ç”¨aggressiveé…ç½®")
    else:
        print(f"  â–³ Need improvement / éœ€è¦æ”¹è¿›")
        print(f"    å»ºè®®ï¼špython main.py --tier_config aggressive")
    
    print(f"{'='*80}")


if __name__ == "__main__":
    main()