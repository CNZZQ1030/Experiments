"""
main.py - é‡æ„ç‰ˆæœ¬
ä¸»ç¨‹åº - åŸºäºæ¢¯åº¦ç¨€ç–åŒ–çš„è”é‚¦å­¦ä¹ æ¿€åŠ±æœºåˆ¶
Main Program - Gradient Sparsification-based Federated Learning Incentive Mechanism

æ ¸å¿ƒæµç¨‹ / Core Workflow:
1. æœåŠ¡å™¨æ”¶é›†å®¢æˆ·ç«¯æ¢¯åº¦ Î”w_i
2. èšåˆå¾—åˆ°å…¨å±€æ¢¯åº¦ Î”w_global = Î£(n_i/n * Î”w_i)
3. å¯¹å…¨å±€æ¢¯åº¦è¿›è¡Œå·®å¼‚åŒ–ç¨€ç– sparse(Î”w_global)
4. å®¢æˆ·ç«¯åº”ç”¨ç¨€ç–æ¢¯åº¦ w_local^(t+1) = w_local^(t) + sparse(Î”w_global)

ä½¿ç”¨æ–¹æ³• / Usage:
    python main.py --dataset cifar10 --distribution non-iid-dir --alpha 0.5
    python main.py --dataset mnist --distribution iid --num_rounds 100
"""

import torch
import numpy as np
import random
import argparse
import os
import sys
import time
import json
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import FederatedConfig, IncentiveConfig, DatasetConfig, DEVICE
from datasets.data_loader import FederatedDataLoader
from models.cnn_model import ModelFactory
from incentive.time_slice import TimeSliceManager
from incentive.membership import MembershipSystem
from utils.metrics import MetricsCalculator
from utils.visualization import Visualizer

# å¯¼å…¥é‡æ„çš„æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯
from federated.server import FederatedServerWithGradientSparsification
from federated.client import FederatedClient


def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


class GradientSparsificationFederatedLearning:
    """
    åŸºäºæ¢¯åº¦ç¨€ç–åŒ–çš„è”é‚¦å­¦ä¹ å®éªŒ
    
    æ ¸å¿ƒåˆ›æ–° / Core Innovation:
    - èšåˆå…¨å±€æ¢¯åº¦è€Œéæ¨¡å‹æƒé‡
    - å¯¹æ¢¯åº¦è¿›è¡Œå·®å¼‚åŒ–ç¨€ç–
    - å®¢æˆ·ç«¯ç´¯ç§¯åº”ç”¨ç¨€ç–æ¢¯åº¦åˆ°æœ¬åœ°æ¨¡å‹
    - ä¿æŒå®¢æˆ·ç«¯æœ¬åœ°ä¸ªæ€§åŒ–
    """
    
    def __init__(self, args):
        """åˆå§‹åŒ–å®éªŒ"""
        self.args = args
        set_seed(args.seed)
        
        self.device = DEVICE
        self.experiment_name = self._generate_experiment_name()
        
        print(f"\n{'='*80}")
        print(f"Federated Learning with Gradient Sparsification Incentive")
        print(f"è”é‚¦å­¦ä¹  - åŸºäºæ¢¯åº¦ç¨€ç–åŒ–çš„æ¿€åŠ±æœºåˆ¶")
        print(f"{'='*80}")
        print(f"Experiment: {self.experiment_name}")
        print(f"Dataset: {args.dataset}")
        print(f"Distribution: {args.distribution}")
        print(f"Clients: {args.num_clients}")
        print(f"Rounds: {args.num_rounds}")
        print(f"Device: {self.device}")
        print(f"\nâœ¨ Gradient Sparsification Configuration:")
        print(f"  Mode: {args.sparsification_mode}")
        print(f"  Lambda: {args.lambda_coef}")
        print(f"  Min Keep Ratio: {args.min_keep_ratio}")
        print(f"  Gradient Application LR: {args.gradient_lr}")
        print(f"\nğŸ“Š Expected Sparsity Ranges:")
        for level, (min_s, max_s) in IncentiveConfig.LEVEL_SPARSITY_RANGES.items():
            keep_min, keep_max = 1.0 - max_s, 1.0 - min_s
            print(f"    {level.capitalize()}: Keep [{keep_min:.2f}, {keep_max:.2f}] "
                  f"(Sparse [{min_s:.2f}, {max_s:.2f}])")
        print(f"{'='*80}")
        
        # æ›´æ–°é…ç½®
        IncentiveConfig.SPARSIFICATION_MODE = args.sparsification_mode
        IncentiveConfig.LAMBDA = args.lambda_coef
        IncentiveConfig.MIN_KEEP_RATIO = args.min_keep_ratio
        
        self._initialize_components()
    
    def _generate_experiment_name(self) -> str:
        """ç”Ÿæˆå®éªŒåç§°"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        dist_suffix = f"_a{self.args.alpha}" if self.args.distribution == "non-iid-dir" else ""
        sparse_suffix = f"_GradSparse_{self.args.sparsification_mode}_l{self.args.lambda_coef}"
        return f"{self.args.dataset}_{self.args.distribution}{dist_suffix}" \
               f"_c{self.args.num_clients}_r{self.args.num_rounds}{sparse_suffix}_{timestamp}"
    
    def _initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        print("\nInitializing components...")
        
        # 1. æ•°æ®åŠ è½½
        print("  [1/6] Loading data...")
        self.data_loader = FederatedDataLoader(
            dataset_name=self.args.dataset,
            num_clients=self.args.num_clients,
            batch_size=self.args.batch_size,
            distribution=self.args.distribution,
            alpha=self.args.alpha
        )
        
        # 2. æ¨¡å‹åˆ›å»º
        print("  [2/6] Creating model...")
        num_classes = DatasetConfig.NUM_CLASSES[self.args.dataset]
        input_channels = DatasetConfig.INPUT_SHAPE[self.args.dataset][0]
        
        self.model = ModelFactory.create_model(
            self.args.dataset,
            num_classes=num_classes,
            input_channels=input_channels
        )
        
        # 3. æœåŠ¡å™¨åˆå§‹åŒ–ï¼ˆæ¢¯åº¦ç¨€ç–åŒ–ç‰ˆæœ¬ï¼‰
        print("  [3/6] Initializing server with gradient sparsification...")
        self.server = FederatedServerWithGradientSparsification(self.model, self.device)
        
        # 4. å®¢æˆ·ç«¯åˆ›å»º
        print("  [4/6] Creating clients...")
        self.clients = {}
        for client_id in tqdm(range(self.args.num_clients), desc="    Creating", leave=False):
            train_loader = self.data_loader.get_client_train_dataloader(client_id)
            test_loader = self.data_loader.get_client_test_dataloader(client_id)
            num_train = self.data_loader.get_num_train_samples(client_id)
            num_test = self.data_loader.get_num_test_samples(client_id)
            
            client = FederatedClient(
                client_id=client_id,
                model=self.model,
                train_dataloader=train_loader,
                test_dataloader=test_loader,
                num_train_samples=num_train,
                num_test_samples=num_test,
                device=self.device
            )
            self.clients[client_id] = client
        
        # 5. æ¿€åŠ±ç³»ç»Ÿ
        print("  [5/6] Initializing incentive system...")
        self.time_slice_manager = TimeSliceManager(
            slice_type="rounds",
            rounds_per_slice=self.args.rounds_per_slice,
            validity_slices=IncentiveConfig.POINTS_VALIDITY_SLICES
        )
        
        self.membership_system = MembershipSystem(
            ranking_percentiles=IncentiveConfig.LEVEL_PERCENTILES
        )
        
        for client_id in range(self.args.num_clients):
            self.membership_system.initialize_client(client_id)
        
        # 6. æŒ‡æ ‡ç³»ç»Ÿ
        print("  [6/6] Initializing metrics...")
        self.metrics_calculator = MetricsCalculator()
        self.visualizer = Visualizer(output_dir="outputs/figures")
        
        print("âœ“ All components initialized")
    
    def compute_standalone_baselines(self):
        """è®¡ç®—ç‹¬ç«‹è®­ç»ƒåŸºå‡†"""
        print(f"\n{'='*80}")
        print(f"Computing Standalone Baselines ({self.args.standalone_epochs} epochs)")
        print(f"{'='*80}")
        
        for client_id, client in tqdm(self.clients.items(), desc="Standalone training"):
            standalone_acc, _ = client.train_standalone(epochs=self.args.standalone_epochs)
            self.metrics_calculator.record_standalone_accuracy(client_id, standalone_acc)
        
        print("âœ“ Standalone baselines computed")
    
    def run_single_round(self, round_num: int) -> dict:
        """
        è¿è¡Œå•è½®è®­ç»ƒ - æ¢¯åº¦ç¨€ç–åŒ–ç‰ˆæœ¬
        
        æ ¸å¿ƒæµç¨‹ / Core Workflow:
        1. å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼Œä¸Šä¼ è®­ç»ƒåçš„æƒé‡
        2. æœåŠ¡å™¨è®¡ç®—å®¢æˆ·ç«¯æ¢¯åº¦ï¼šÎ”w_i = w_i^new - w_i^old
        3. èšåˆå…¨å±€æ¢¯åº¦ï¼šÎ”w_global = Î£(n_i/n * Î”w_i)
        4. è®¡ç®—è´¡çŒ®åº¦å’Œæ›´æ–°ä¼šå‘˜ç­‰çº§
        5. å¯¹å…¨å±€æ¢¯åº¦è¿›è¡Œå·®å¼‚åŒ–ç¨€ç–
        6. å®¢æˆ·ç«¯åº”ç”¨ç¨€ç–æ¢¯åº¦ï¼šw_local = w_local + lr * sparse(Î”w_global)
        """
        round_start = time.time()
        
        selected_clients = list(range(self.args.num_clients))
        self.server.reset_round()
        client_accuracies = {}
        
        show_details = (round_num % max(1, self.args.num_rounds // 10) == 0) or \
                      round_num == 1 or round_num == self.args.num_rounds
        
        if show_details:
            print(f"\n{'='*80}")
            print(f"Round {round_num}/{self.args.num_rounds}")
            print(f"{'='*80}")
        
        # ========== æ­¥éª¤1: å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ ==========
        for client_id in tqdm(selected_clients, 
                            desc=f"Round {round_num} - Training",
                            leave=False):
            client = self.clients[client_id]
            
            # ç¬¬ä¸€è½®éœ€è¦åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹
            if round_num == 1:
                global_weights = self.server.get_global_model_weights()
            else:
                global_weights = None  # åç»­è½®æ¬¡ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            
            # æœ¬åœ°è®­ç»ƒï¼ˆå®¢æˆ·ç«¯ä¿æŒæœ¬åœ°æ¨¡å‹çŠ¶æ€ï¼‰
            updated_weights, train_info = client.train_federated(
                global_weights=global_weights,
                epochs=self.args.local_epochs,
                lr=self.args.learning_rate
            )
            
            # æœåŠ¡å™¨æ”¶é›†æ›´æ–°ï¼ˆå†…éƒ¨è®¡ç®—æ¢¯åº¦ï¼‰
            self.server.collect_client_updates(client_id, updated_weights, train_info)
            
            # è®°å½•å‡†ç¡®ç‡
            federated_acc = train_info['federated_accuracy']
            self.metrics_calculator.record_federated_accuracy(client_id, federated_acc)
            client_accuracies[client_id] = federated_acc
        
        # ========== æ­¥éª¤2: èšåˆå…¨å±€æ¢¯åº¦ ==========
        self.server.update_global_model()
        
        # ========== æ­¥éª¤3: è®¡ç®—è´¡çŒ®åº¦ ==========
        contributions = self.server.calculate_all_contributions(round_num)
        
        # ========== æ­¥éª¤4: æ—¶é—´ç‰‡ç§¯åˆ†å’Œä¼šå‘˜ç­‰çº§ ==========
        all_active_points = {}
        for client_id, contribution in contributions.items():
            active_points = self.time_slice_manager.add_contribution_points(
                client_id, round_num, contribution
            )
            all_active_points[client_id] = active_points
        
        # æ›´æ–°ä¼šå‘˜ç­‰çº§
        new_levels = self.membership_system.update_all_memberships_by_ranking(all_active_points)
        for client_id, new_level in new_levels.items():
            self.clients[client_id].update_membership_level(new_level)
        
        # æ¸…ç†è¿‡æœŸç§¯åˆ†
        current_slice = self.time_slice_manager.get_current_slice(round_num)
        if round_num > 1:
            prev_slice = self.time_slice_manager.get_current_slice(round_num - 1)
            if current_slice != prev_slice:
                cleaned = self.time_slice_manager.clean_expired_points(round_num)
                if cleaned and show_details:
                    print(f"  Time slice changed: {prev_slice} â†’ {current_slice}")
                
                # é‡æ–°è®¡ç®—ç­‰çº§
                updated_points = self.time_slice_manager.get_all_client_active_points(round_num)
                new_levels = self.membership_system.update_all_memberships_by_ranking(updated_points)
                for client_id, new_level in new_levels.items():
                    self.clients[client_id].update_membership_level(new_level)
        
        # ========== æ­¥éª¤5: åˆ†å‘ç¨€ç–åŒ–æ¢¯åº¦ ==========
        sparsified_gradients = self.server.distribute_sparsified_gradients(new_levels)
        
        # ========== æ­¥éª¤6: å®¢æˆ·ç«¯åº”ç”¨ç¨€ç–æ¢¯åº¦ ==========
        for client_id in tqdm(selected_clients, 
                            desc=f"Round {round_num} - Applying gradients",
                            leave=False):
            if client_id in sparsified_gradients:
                sparse_gradient = sparsified_gradients[client_id]
                self.clients[client_id].apply_gradient_update(
                    sparse_gradient, 
                    learning_rate=self.args.gradient_lr
                )
        
        round_time = time.time() - round_start
        
        # æ‰“å°è½®æ¬¡æ‘˜è¦
        if show_details:
            round_summary = self.server.get_round_summary(round_num)
            
            if client_accuracies:
                accs = list(client_accuracies.values())
                print(f"\nğŸ“Š Performance:")
                print(f"  Avg Accuracy: {np.mean(accs):.4f}")
                print(f"  Max Accuracy: {np.max(accs):.4f}")
                print(f"  Min Accuracy: {np.min(accs):.4f}")
            
            print(f"\nğŸ¯ Contributions (CGSV):")
            contrib_stats = round_summary['contribution_stats']
            print(f"  Mean: {contrib_stats['mean']:.4f}, Std: {contrib_stats['std']:.4f}")
            print(f"  Range: [{contrib_stats['min']:.4f}, {contrib_stats['max']:.4f}]")
            
            if 'sparsification_stats' in round_summary and round_summary['sparsification_stats']:
                sparse_stats = round_summary['sparsification_stats']['by_level']
                print(f"\nâœ‚ï¸  Gradient Sparsification Statistics:")
                for level in ['diamond', 'gold', 'silver', 'bronze']:
                    if level in sparse_stats:
                        ls = sparse_stats[level]
                        print(f"  {level.capitalize()}: Keep={ls['avg_keep_ratio']:.3f}, "
                              f"Sparse={ls['avg_sparsity_rate']:.3f} (n={ls['count']})")
            
            print(f"\nâ±ï¸  Time: {round_time:.2f}s")
            
            if round_num % 10 == 0 or round_num == self.args.num_rounds:
                self.membership_system.print_membership_distribution()
        
        # è®°å½•æŒ‡æ ‡
        round_metrics = {
            'round': round_num,
            'time_consumption': round_time,
            'num_selected_clients': len(selected_clients),
            'contributions': contributions.copy(),
            'client_accuracies': client_accuracies.copy(),
            'current_slice': current_slice,
            'active_points': all_active_points.copy(),
            'membership_levels': new_levels.copy(),
            'sparsification_stats': self.server.sparsification_distributor.get_sparsification_statistics()
        }
        
        self.metrics_calculator.record_round(round_metrics)
        return round_metrics
    
    def run_experiment(self):
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        print(f"\n{'='*80}")
        print(f"Starting Experiment: {self.experiment_name}")
        print(f"{'='*80}")
        
        # ç‹¬ç«‹è®­ç»ƒåŸºå‡†
        self.compute_standalone_baselines()
        
        # è”é‚¦å­¦ä¹ è®­ç»ƒ
        print(f"\n{'='*80}")
        print("Federated Learning Training with Gradient Sparsification")
        print(f"{'='*80}")
        
        for round_num in range(1, self.args.num_rounds + 1):
            self.run_single_round(round_num)
        
        print(f"\n{'='*80}")
        print("Training Complete")
        print(f"{'='*80}")
        
        # æœ€ç»ˆæŒ‡æ ‡
        final_metrics = self.metrics_calculator.calculate_final_metrics()
        
        # æ‰“å°æ‘˜è¦
        self.metrics_calculator.print_summary()
        self.time_slice_manager.print_summary(self.args.num_rounds)
        self.server.print_contribution_summary()
        self.membership_system.print_membership_distribution()
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._generate_visualizations(final_metrics)
        
        # ä¿å­˜ç»“æœ
        self._save_results(final_metrics)
        
        return final_metrics
    
    def _generate_visualizations(self, final_metrics):
        """ç”Ÿæˆå¯è§†åŒ–"""
        print(f"\n{'='*80}")
        print("Generating Visualizations")
        print(f"{'='*80}")
        
        contributions_history = [rm.get('contributions', {}) 
                                for rm in self.metrics_calculator.round_metrics]
        
        metrics_history = {
            'rounds': list(range(1, len(self.metrics_calculator.avg_client_accuracies) + 1)),
            'avg_client_accuracy': self.metrics_calculator.avg_client_accuracies,
            'max_client_accuracy': self.metrics_calculator.max_client_accuracies,
            'time_per_round': self.metrics_calculator.time_consumptions,
            'contributions': contributions_history,
            'raw_contributions': contributions_history
        }
        
        self.visualizer.generate_all_plots(final_metrics, metrics_history, self.experiment_name)
        print("âœ“ Visualizations generated")
    
    def _save_results(self, final_metrics):
        """ä¿å­˜ç»“æœ"""
        results_dir = "outputs/results"
        os.makedirs(results_dir, exist_ok=True)
        
        results_path = os.path.join(results_dir, f"{self.experiment_name}_results.json")
        
        save_data = {
            'experiment_name': self.experiment_name,
            'methodology': 'Gradient Sparsification-based Differentiated Distribution',
            'configuration': {
                'dataset': self.args.dataset,
                'num_clients': self.args.num_clients,
                'num_rounds': self.args.num_rounds,
                'distribution': self.args.distribution,
                'alpha': self.args.alpha,
                'rounds_per_slice': self.args.rounds_per_slice,
                'local_epochs': self.args.local_epochs,
                'batch_size': self.args.batch_size,
                'learning_rate': self.args.learning_rate,
                'gradient_lr': self.args.gradient_lr,
                'standalone_epochs': self.args.standalone_epochs,
                'seed': self.args.seed
            },
            'sparsification_config': {
                'mode': self.args.sparsification_mode,
                'lambda': self.args.lambda_coef,
                'min_keep_ratio': self.args.min_keep_ratio,
                'sparsity_ranges': IncentiveConfig.LEVEL_SPARSITY_RANGES,
                'level_percentiles': IncentiveConfig.LEVEL_PERCENTILES
            },
            'final_metrics': final_metrics,
            'round_metrics': self.metrics_calculator.round_metrics[-10:],
            'membership_statistics': self.membership_system.get_membership_statistics(),
            'contribution_statistics': self.server.get_contribution_statistics(),
            'sparsification_statistics': self.server.sparsification_distributor.get_sparsification_statistics()
        }
        
        with open(results_path, 'w') as f:
            json.dump(save_data, f, indent=2, default=str)
        
        print(f"âœ“ Results saved to: {results_path}")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='Federated Learning with Gradient Sparsification Incentive\n'
                    'è”é‚¦å­¦ä¹  - åŸºäºæ¢¯åº¦ç¨€ç–åŒ–çš„æ¿€åŠ±æœºåˆ¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples / ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€å®éªŒ - MNIST + IID
  python main.py --dataset mnist --distribution iid
  
  # Non-IIDå®éªŒ - CIFAR10
  python main.py --dataset cifar10 --distribution non-iid-dir --alpha 0.5
  
  # è°ƒæ•´ç¨€ç–åŒ–å‚æ•°
  python main.py --dataset cifar10 --sparsification_mode magnitude --lambda_coef 2.0
  
  # å¤§è§„æ¨¡å®éªŒ
  python main.py --dataset cifar10 --num_clients 100 --num_rounds 100 \\
                 --sparsification_mode structured --lambda_coef 3.0
        """
    )
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument('--dataset', type=str, default='cifar10',
                       choices=['mnist', 'fashion-mnist', 'cifar10', 'cifar100'],
                       help='Dataset name')
    
    parser.add_argument('--num_clients', type=int, default=100,
                       help='Number of clients')
    
    # æ•°æ®åˆ†å¸ƒ
    parser.add_argument('--distribution', type=str, default='non-iid-dir',
                       choices=['iid', 'non-iid-dir'],
                       help='Data distribution type')
    
    parser.add_argument('--alpha', type=float, default=0.5,
                       help='Dirichlet alpha for non-iid')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--num_rounds', type=int, default=50,
                       help='Number of communication rounds')
    
    parser.add_argument('--local_epochs', type=int, default=5,
                       help='Local epochs per round')
    
    parser.add_argument('--batch_size', type=int, default=32,
                       help='Batch size')
    
    parser.add_argument('--learning_rate', type=float, default=0.01,
                       help='Learning rate for local training')
    
    parser.add_argument('--gradient_lr', type=float, default=1.0,
                       help='Learning rate for applying sparse gradients (é€šå¸¸è®¾ä¸º1.0)')
    
    parser.add_argument('--standalone_epochs', type=int, default=20,
                       help='Standalone training epochs')
    
    # æ—¶é—´ç‰‡å‚æ•°
    parser.add_argument('--rounds_per_slice', type=int, default=5,
                       help='Rounds per time slice')
    
    # ç¨€ç–åŒ–å‚æ•°
    parser.add_argument('--sparsification_mode', type=str, default='magnitude',
                       choices=['magnitude', 'random', 'structured'],
                       help='Sparsification mode')
    
    parser.add_argument('--lambda_coef', type=float, default=2.0,
                       help='Lambda coefficient for keep ratio calculation')
    
    parser.add_argument('--min_keep_ratio', type=float, default=0.1,
                       help='Minimum keep ratio')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è¿è¡Œå®éªŒ
    experiment = GradientSparsificationFederatedLearning(args)
    final_metrics = experiment.run_experiment()
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print(f"\n{'='*80}")
    print("ğŸ‰ Experiment Completed!")
    print(f"{'='*80}")
    print(f"Experiment: {experiment.experiment_name}")
    print(f"\nğŸ“ˆ Key Results:")
    print(f"  Methodology: Gradient Sparsification")
    print(f"  Final Avg Accuracy: {final_metrics['client_accuracy']['avg_final']:.4f}")
    print(f"  PCC: {final_metrics['pcc']:.4f}")
    print(f"  IPR: {final_metrics['ipr']['final_ipr']:.4f} ({final_metrics['ipr']['ipr_percentage']:.2f}%)")
    print(f"  Total Time: {final_metrics['time_consumption']['total']:.2f}s")
    print(f"{'='*80}")


if __name__ == "__main__":
    main()